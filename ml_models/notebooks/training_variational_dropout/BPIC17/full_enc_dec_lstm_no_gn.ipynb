{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T22:34:52.780137Z",
     "iopub.status.busy": "2025-02-14T22:34:52.780012Z",
     "iopub.status.idle": "2025-02-14T22:34:53.490466Z",
     "shell.execute_reply": "2025-02-14T22:34:53.490214Z"
    }
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "sys.path.insert(1, '../..')\n",
    "sys.path.insert(2, '../../..')\n",
    "sys.path.insert(3, '../../../..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T22:34:53.492193Z",
     "iopub.status.busy": "2025-02-14T22:34:53.492067Z",
     "iopub.status.idle": "2025-02-14T22:34:59.658880Z",
     "shell.execute_reply": "2025-02-14T22:34:59.658593Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'event_log_loader.new_event_log_loader.EventLogDataset'>\n",
      "<class 'event_log_loader.new_event_log_loader.EventLogDataset'>\n"
     ]
    }
   ],
   "source": [
    "# Path to your pickle file (saved with torch.save)\n",
    "file_path_train = '../../../../encoded_data/helpdesk_all_5_train.pkl'\n",
    "# Load the dataset using torch.load\n",
    "BPIC_17_train_dataset = torch.load(file_path_train, weights_only=False)\n",
    "# Check the type of the loaded dataset\n",
    "print(type(BPIC_17_train_dataset))  # Should output something like <class 'torch.utils.data.dataset.TensorDataset'>\n",
    "\n",
    "# Path to your pickle file (saved with torch.save)\n",
    "file_path_val = '../../../../encoded_data/helpdesk_all_5_val.pkl'\n",
    "# Load the dataset using torch.load\n",
    "BPIC_17_val_dataset = torch.load(file_path_val, weights_only=False)\n",
    "# Check the type of the loaded dataset\n",
    "print(type(BPIC_17_val_dataset))  # Should output something like <class 'torch.utils.data.dataset.TensorDataset'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Data Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T22:34:59.660002Z",
     "iopub.status.busy": "2025-02-14T22:34:59.659841Z",
     "iopub.status.idle": "2025-02-14T22:34:59.662546Z",
     "shell.execute_reply": "2025-02-14T22:34:59.662332Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Activity', 16, {'Assign seriousness': 1, 'Closed': 2, 'Create SW anomaly': 3, 'DUPLICATE': 4, 'EOS': 5, 'INVALID': 6, 'Insert ticket': 7, 'RESOLVED': 8, 'Require upgrade': 9, 'Resolve SW anomaly': 10, 'Resolve ticket': 11, 'Schedule intervention': 12, 'Take in charge ticket': 13, 'VERIFIED': 14, 'Wait': 15}), ('Resource', 24, {'EOS': 1, 'Value 1': 2, 'Value 10': 3, 'Value 11': 4, 'Value 12': 5, 'Value 13': 6, 'Value 14': 7, 'Value 15': 8, 'Value 16': 9, 'Value 17': 10, 'Value 18': 11, 'Value 19': 12, 'Value 2': 13, 'Value 20': 14, 'Value 21': 15, 'Value 22': 16, 'Value 3': 17, 'Value 4': 18, 'Value 5': 19, 'Value 6': 20, 'Value 7': 21, 'Value 8': 22, 'Value 9': 23}), ('Variant index', 175, {'1.0': 1, '10.0': 2, '100.0': 3, '103.0': 4, '104.0': 5, '107.0': 6, '109.0': 7, '11.0': 8, '110.0': 9, '112.0': 10, '113.0': 11, '114.0': 12, '115.0': 13, '117.0': 14, '118.0': 15, '12.0': 16, '120.0': 17, '122.0': 18, '123.0': 19, '124.0': 20, '125.0': 21, '126.0': 22, '127.0': 23, '129.0': 24, '13.0': 25, '130.0': 26, '131.0': 27, '134.0': 28, '135.0': 29, '137.0': 30, '138.0': 31, '139.0': 32, '14.0': 33, '140.0': 34, '141.0': 35, '143.0': 36, '145.0': 37, '147.0': 38, '149.0': 39, '15.0': 40, '150.0': 41, '151.0': 42, '152.0': 43, '153.0': 44, '154.0': 45, '155.0': 46, '156.0': 47, '157.0': 48, '158.0': 49, '16.0': 50, '162.0': 51, '163.0': 52, '164.0': 53, '165.0': 54, '167.0': 55, '168.0': 56, '169.0': 57, '17.0': 58, '170.0': 59, '172.0': 60, '173.0': 61, '175.0': 62, '176.0': 63, '179.0': 64, '18.0': 65, '180.0': 66, '181.0': 67, '182.0': 68, '183.0': 69, '188.0': 70, '19.0': 71, '192.0': 72, '193.0': 73, '194.0': 74, '195.0': 75, '197.0': 76, '199.0': 77, '2.0': 78, '20.0': 79, '202.0': 80, '203.0': 81, '204.0': 82, '205.0': 83, '207.0': 84, '208.0': 85, '21.0': 86, '211.0': 87, '212.0': 88, '214.0': 89, '217.0': 90, '22.0': 91, '220.0': 92, '222.0': 93, '225.0': 94, '23.0': 95, '24.0': 96, '25.0': 97, '26.0': 98, '27.0': 99, '28.0': 100, '29.0': 101, '3.0': 102, '30.0': 103, '31.0': 104, '32.0': 105, '33.0': 106, '34.0': 107, '35.0': 108, '36.0': 109, '37.0': 110, '38.0': 111, '39.0': 112, '4.0': 113, '40.0': 114, '41.0': 115, '42.0': 116, '43.0': 117, '44.0': 118, '45.0': 119, '46.0': 120, '47.0': 121, '48.0': 122, '49.0': 123, '5.0': 124, '50.0': 125, '51.0': 126, '52.0': 127, '53.0': 128, '54.0': 129, '55.0': 130, '56.0': 131, '57.0': 132, '58.0': 133, '59.0': 134, '6.0': 135, '60.0': 136, '61.0': 137, '62.0': 138, '63.0': 139, '64.0': 140, '65.0': 141, '66.0': 142, '67.0': 143, '68.0': 144, '69.0': 145, '7.0': 146, '70.0': 147, '71.0': 148, '72.0': 149, '73.0': 150, '74.0': 151, '75.0': 152, '76.0': 153, '77.0': 154, '78.0': 155, '79.0': 156, '8.0': 157, '81.0': 158, '83.0': 159, '84.0': 160, '85.0': 161, '86.0': 162, '87.0': 163, '88.0': 164, '89.0': 165, '9.0': 166, '90.0': 167, '91.0': 168, '93.0': 169, '94.0': 170, '95.0': 171, '97.0': 172, '99.0': 173, nan: 174}), ('seriousness', 3, {'EOS': 1, 'Value 1': 2}), ('customer', 361, {'EOS': 1, 'Value 1': 2, 'Value 10': 3, 'Value 100': 4, 'Value 101': 5, 'Value 102': 6, 'Value 103': 7, 'Value 104': 8, 'Value 105': 9, 'Value 106': 10, 'Value 107': 11, 'Value 108': 12, 'Value 11': 13, 'Value 110': 14, 'Value 111': 15, 'Value 112': 16, 'Value 113': 17, 'Value 114': 18, 'Value 115': 19, 'Value 116': 20, 'Value 117': 21, 'Value 118': 22, 'Value 119': 23, 'Value 12': 24, 'Value 120': 25, 'Value 121': 26, 'Value 122': 27, 'Value 123': 28, 'Value 124': 29, 'Value 125': 30, 'Value 126': 31, 'Value 127': 32, 'Value 129': 33, 'Value 13': 34, 'Value 131': 35, 'Value 132': 36, 'Value 133': 37, 'Value 134': 38, 'Value 135': 39, 'Value 136': 40, 'Value 137': 41, 'Value 138': 42, 'Value 139': 43, 'Value 14': 44, 'Value 140': 45, 'Value 142': 46, 'Value 143': 47, 'Value 144': 48, 'Value 145': 49, 'Value 146': 50, 'Value 147': 51, 'Value 148': 52, 'Value 149': 53, 'Value 15': 54, 'Value 150': 55, 'Value 151': 56, 'Value 152': 57, 'Value 153': 58, 'Value 154': 59, 'Value 155': 60, 'Value 156': 61, 'Value 157': 62, 'Value 158': 63, 'Value 16': 64, 'Value 160': 65, 'Value 161': 66, 'Value 162': 67, 'Value 163': 68, 'Value 164': 69, 'Value 165': 70, 'Value 166': 71, 'Value 167': 72, 'Value 168': 73, 'Value 169': 74, 'Value 17': 75, 'Value 171': 76, 'Value 172': 77, 'Value 173': 78, 'Value 174': 79, 'Value 175': 80, 'Value 176': 81, 'Value 177': 82, 'Value 178': 83, 'Value 179': 84, 'Value 18': 85, 'Value 180': 86, 'Value 181': 87, 'Value 182': 88, 'Value 183': 89, 'Value 184': 90, 'Value 185': 91, 'Value 186': 92, 'Value 187': 93, 'Value 188': 94, 'Value 189': 95, 'Value 19': 96, 'Value 190': 97, 'Value 191': 98, 'Value 192': 99, 'Value 193': 100, 'Value 194': 101, 'Value 195': 102, 'Value 196': 103, 'Value 197': 104, 'Value 198': 105, 'Value 199': 106, 'Value 2': 107, 'Value 20': 108, 'Value 200': 109, 'Value 201': 110, 'Value 202': 111, 'Value 203': 112, 'Value 204': 113, 'Value 205': 114, 'Value 206': 115, 'Value 207': 116, 'Value 208': 117, 'Value 209': 118, 'Value 21': 119, 'Value 210': 120, 'Value 211': 121, 'Value 213': 122, 'Value 214': 123, 'Value 215': 124, 'Value 216': 125, 'Value 217': 126, 'Value 218': 127, 'Value 219': 128, 'Value 22': 129, 'Value 220': 130, 'Value 221': 131, 'Value 222': 132, 'Value 223': 133, 'Value 224': 134, 'Value 225': 135, 'Value 226': 136, 'Value 227': 137, 'Value 228': 138, 'Value 229': 139, 'Value 23': 140, 'Value 230': 141, 'Value 231': 142, 'Value 232': 143, 'Value 233': 144, 'Value 234': 145, 'Value 235': 146, 'Value 236': 147, 'Value 237': 148, 'Value 238': 149, 'Value 239': 150, 'Value 24': 151, 'Value 240': 152, 'Value 241': 153, 'Value 242': 154, 'Value 243': 155, 'Value 244': 156, 'Value 245': 157, 'Value 246': 158, 'Value 247': 159, 'Value 248': 160, 'Value 249': 161, 'Value 25': 162, 'Value 250': 163, 'Value 251': 164, 'Value 252': 165, 'Value 253': 166, 'Value 254': 167, 'Value 255': 168, 'Value 256': 169, 'Value 258': 170, 'Value 259': 171, 'Value 26': 172, 'Value 260': 173, 'Value 261': 174, 'Value 262': 175, 'Value 263': 176, 'Value 264': 177, 'Value 265': 178, 'Value 266': 179, 'Value 267': 180, 'Value 269': 181, 'Value 27': 182, 'Value 271': 183, 'Value 272': 184, 'Value 273': 185, 'Value 274': 186, 'Value 275': 187, 'Value 276': 188, 'Value 277': 189, 'Value 278': 190, 'Value 279': 191, 'Value 28': 192, 'Value 280': 193, 'Value 281': 194, 'Value 282': 195, 'Value 283': 196, 'Value 284': 197, 'Value 285': 198, 'Value 286': 199, 'Value 287': 200, 'Value 288': 201, 'Value 289': 202, 'Value 29': 203, 'Value 292': 204, 'Value 293': 205, 'Value 294': 206, 'Value 296': 207, 'Value 297': 208, 'Value 298': 209, 'Value 299': 210, 'Value 3': 211, 'Value 30': 212, 'Value 300': 213, 'Value 301': 214, 'Value 302': 215, 'Value 303': 216, 'Value 304': 217, 'Value 305': 218, 'Value 306': 219, 'Value 307': 220, 'Value 308': 221, 'Value 309': 222, 'Value 31': 223, 'Value 310': 224, 'Value 311': 225, 'Value 312': 226, 'Value 313': 227, 'Value 314': 228, 'Value 315': 229, 'Value 316': 230, 'Value 317': 231, 'Value 318': 232, 'Value 319': 233, 'Value 32': 234, 'Value 320': 235, 'Value 321': 236, 'Value 322': 237, 'Value 323': 238, 'Value 324': 239, 'Value 325': 240, 'Value 326': 241, 'Value 327': 242, 'Value 328': 243, 'Value 329': 244, 'Value 33': 245, 'Value 331': 246, 'Value 332': 247, 'Value 333': 248, 'Value 334': 249, 'Value 335': 250, 'Value 336': 251, 'Value 337': 252, 'Value 338': 253, 'Value 339': 254, 'Value 34': 255, 'Value 340': 256, 'Value 342': 257, 'Value 343': 258, 'Value 344': 259, 'Value 345': 260, 'Value 346': 261, 'Value 348': 262, 'Value 349': 263, 'Value 35': 264, 'Value 350': 265, 'Value 351': 266, 'Value 352': 267, 'Value 353': 268, 'Value 356': 269, 'Value 357': 270, 'Value 36': 271, 'Value 362': 272, 'Value 363': 273, 'Value 364': 274, 'Value 365': 275, 'Value 366': 276, 'Value 368': 277, 'Value 369': 278, 'Value 37': 279, 'Value 370': 280, 'Value 374': 281, 'Value 375': 282, 'Value 376': 283, 'Value 377': 284, 'Value 379': 285, 'Value 38': 286, 'Value 380': 287, 'Value 383': 288, 'Value 384': 289, 'Value 386': 290, 'Value 388': 291, 'Value 389': 292, 'Value 39': 293, 'Value 390': 294, 'Value 393': 295, 'Value 396': 296, 'Value 4': 297, 'Value 40': 298, 'Value 41': 299, 'Value 42': 300, 'Value 43': 301, 'Value 44': 302, 'Value 45': 303, 'Value 46': 304, 'Value 47': 305, 'Value 48': 306, 'Value 49': 307, 'Value 5': 308, 'Value 50': 309, 'Value 51': 310, 'Value 52': 311, 'Value 53': 312, 'Value 54': 313, 'Value 55': 314, 'Value 56': 315, 'Value 57': 316, 'Value 58': 317, 'Value 59': 318, 'Value 6': 319, 'Value 60': 320, 'Value 61': 321, 'Value 62': 322, 'Value 63': 323, 'Value 64': 324, 'Value 65': 325, 'Value 66': 326, 'Value 67': 327, 'Value 68': 328, 'Value 69': 329, 'Value 7': 330, 'Value 70': 331, 'Value 71': 332, 'Value 72': 333, 'Value 73': 334, 'Value 74': 335, 'Value 75': 336, 'Value 76': 337, 'Value 77': 338, 'Value 78': 339, 'Value 79': 340, 'Value 8': 341, 'Value 80': 342, 'Value 81': 343, 'Value 82': 344, 'Value 83': 345, 'Value 85': 346, 'Value 86': 347, 'Value 87': 348, 'Value 88': 349, 'Value 89': 350, 'Value 9': 351, 'Value 90': 352, 'Value 91': 353, 'Value 92': 354, 'Value 93': 355, 'Value 94': 356, 'Value 96': 357, 'Value 97': 358, 'Value 98': 359, 'Value 99': 360}), ('product', 23, {'EOS': 1, 'Value 1': 2, 'Value 10': 3, 'Value 11': 4, 'Value 12': 5, 'Value 13': 6, 'Value 14': 7, 'Value 15': 8, 'Value 16': 9, 'Value 17': 10, 'Value 18': 11, 'Value 19': 12, 'Value 2': 13, 'Value 20': 14, 'Value 21': 15, 'Value 3': 16, 'Value 4': 17, 'Value 5': 18, 'Value 6': 19, 'Value 7': 20, 'Value 8': 21, 'Value 9': 22}), ('responsible_section', 9, {'EOS': 1, 'Value 1': 2, 'Value 2': 3, 'Value 3': 4, 'Value 4': 5, 'Value 5': 6, 'Value 6': 7, 'Value 7': 8}), ('seriousness_2', 6, {'EOS': 1, 'Value 1': 2, 'Value 2': 3, 'Value 3': 4, 'Value 4': 5}), ('service_level', 6, {'EOS': 1, 'Value 1': 2, 'Value 2': 3, 'Value 3': 4, 'Value 4': 5}), ('service_type', 6, {'EOS': 1, 'Value 1': 2, 'Value 2': 3, 'Value 3': 4, 'Value 4': 5}), ('support_section', 8, {'EOS': 1, 'Value 1': 2, 'Value 2': 3, 'Value 3': 4, 'Value 4': 5, 'Value 5': 6, 'Value 6': 7}), ('workgroup', 6, {'EOS': 1, 'Value 1': 2, 'Value 2': 3, 'Value 3': 4, 'Value 4': 5})]\n",
      "[('case_elapsed_time', 1, {}), ('event_elapsed_time', 1, {}), ('day_in_week', 1, {}), ('seconds_in_day', 1, {})]\n",
      "BPIC 17 (5) Categorical feature: Activity, Index position in categorical data list: 0\n",
      "BPIC 17 (5) Total Amount of Category labels: 16\n",
      "BPIC 17 (5) Categorical feature: Resource, Index position in categorical data list: 1\n",
      "BPIC 17 (5) Total Amount of Category labels: 24\n",
      "BPIC 17 (5) Categorical feature: Variant index, Index position in categorical data list: 2\n",
      "BPIC 17 (5) Total Amount of Category labels: 175\n",
      "BPIC 17 (5) Categorical feature: seriousness, Index position in categorical data list: 3\n",
      "BPIC 17 (5) Total Amount of Category labels: 3\n",
      "BPIC 17 (5) Categorical feature: customer, Index position in categorical data list: 4\n",
      "BPIC 17 (5) Total Amount of Category labels: 361\n",
      "BPIC 17 (5) Categorical feature: product, Index position in categorical data list: 5\n",
      "BPIC 17 (5) Total Amount of Category labels: 23\n",
      "BPIC 17 (5) Categorical feature: responsible_section, Index position in categorical data list: 6\n",
      "BPIC 17 (5) Total Amount of Category labels: 9\n",
      "BPIC 17 (5) Categorical feature: seriousness_2, Index position in categorical data list: 7\n",
      "BPIC 17 (5) Total Amount of Category labels: 6\n",
      "BPIC 17 (5) Categorical feature: service_level, Index position in categorical data list: 8\n",
      "BPIC 17 (5) Total Amount of Category labels: 6\n",
      "BPIC 17 (5) Categorical feature: service_type, Index position in categorical data list: 9\n",
      "BPIC 17 (5) Total Amount of Category labels: 6\n",
      "BPIC 17 (5) Categorical feature: support_section, Index position in categorical data list: 10\n",
      "BPIC 17 (5) Total Amount of Category labels: 8\n",
      "BPIC 17 (5) Categorical feature: workgroup, Index position in categorical data list: 11\n",
      "BPIC 17 (5) Total Amount of Category labels: 6\n",
      "\n",
      "\n",
      "BPIC 17 (5) Numerical feature: case_elapsed_time, Index position in categorical data list: 0\n",
      "BPIC 17 (5) Amount Category Lables: 1\n",
      "BPIC 17 (5) Numerical feature: event_elapsed_time, Index position in categorical data list: 1\n",
      "BPIC 17 (5) Amount Category Lables: 1\n",
      "BPIC 17 (5) Numerical feature: day_in_week, Index position in categorical data list: 2\n",
      "BPIC 17 (5) Amount Category Lables: 1\n",
      "BPIC 17 (5) Numerical feature: seconds_in_day, Index position in categorical data list: 3\n",
      "BPIC 17 (5) Amount Category Lables: 1\n"
     ]
    }
   ],
   "source": [
    "# BPIC 17 Dataset Categories, Features:\n",
    "\n",
    "bpic_17_all_categories = BPIC_17_train_dataset.all_categories\n",
    "\n",
    "bpic_17_all_categories_cat = bpic_17_all_categories[0]\n",
    "print(bpic_17_all_categories_cat)\n",
    "\n",
    "bpic_17_all_categories_num = bpic_17_all_categories[1]\n",
    "print(bpic_17_all_categories_num)\n",
    "\n",
    "for i, cat in enumerate(bpic_17_all_categories_cat):\n",
    "     print(f\"BPIC 17 (5) Categorical feature: {cat[0]}, Index position in categorical data list: {i}\")\n",
    "     print(f\"BPIC 17 (5) Total Amount of Category labels: {cat[1]}\")\n",
    "print('\\n')    \n",
    "for i, num in enumerate(bpic_17_all_categories_num):\n",
    "     print(f\"BPIC 17 (5) Numerical feature: {num[0]}, Index position in categorical data list: {i}\")\n",
    "     print(f\"BPIC 17 (5) Amount Category Lables: {num[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Features for Encoder and Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T22:34:59.663433Z",
     "iopub.status.busy": "2025-02-14T22:34:59.663296Z",
     "iopub.status.idle": "2025-02-14T22:34:59.665427Z",
     "shell.execute_reply": "2025-02-14T22:34:59.665229Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input features encoder:  [['Activity', 'Resource', 'Variant index', 'seriousness', 'customer', 'product', 'responsible_section', 'seriousness_2', 'service_level', 'service_type', 'support_section', 'workgroup'], ['case_elapsed_time', 'event_elapsed_time', 'day_in_week', 'seconds_in_day']]\n",
      "Features decoder:  [['Activity', 'Resource', 'Variant index', 'seriousness', 'customer', 'product', 'responsible_section', 'seriousness_2', 'service_level', 'service_type', 'support_section', 'workgroup'], ['case_elapsed_time', 'event_elapsed_time', 'day_in_week', 'seconds_in_day']]\n"
     ]
    }
   ],
   "source": [
    "# Create lists with name of Encoder features (input) and decoder features (input & output)\n",
    "\n",
    "# Encoder features:\n",
    "enc_feat_cat = []\n",
    "enc_feat_num = []\n",
    "for cat in bpic_17_all_categories_cat:\n",
    "    enc_feat_cat.append(cat[0])\n",
    "for num in bpic_17_all_categories_num:\n",
    "    enc_feat_num.append(num[0])\n",
    "enc_feat = [enc_feat_cat, enc_feat_num]\n",
    "print(\"Input features encoder: \", enc_feat)\n",
    "\n",
    "# Decoder features:\n",
    "dec_feat_cat = enc_feat_cat\n",
    "dec_feat_num = enc_feat_num\n",
    "dec_feat = [dec_feat_cat, dec_feat_num]\n",
    "print(\"Features decoder: \", dec_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T22:34:59.666216Z",
     "iopub.status.busy": "2025-02-14T22:34:59.666133Z",
     "iopub.status.idle": "2025-02-14T22:34:59.676043Z",
     "shell.execute_reply": "2025-02-14T22:34:59.675830Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set categories:  ([('Activity', 16, {'Assign seriousness': 1, 'Closed': 2, 'Create SW anomaly': 3, 'DUPLICATE': 4, 'EOS': 5, 'INVALID': 6, 'Insert ticket': 7, 'RESOLVED': 8, 'Require upgrade': 9, 'Resolve SW anomaly': 10, 'Resolve ticket': 11, 'Schedule intervention': 12, 'Take in charge ticket': 13, 'VERIFIED': 14, 'Wait': 15}), ('Resource', 24, {'EOS': 1, 'Value 1': 2, 'Value 10': 3, 'Value 11': 4, 'Value 12': 5, 'Value 13': 6, 'Value 14': 7, 'Value 15': 8, 'Value 16': 9, 'Value 17': 10, 'Value 18': 11, 'Value 19': 12, 'Value 2': 13, 'Value 20': 14, 'Value 21': 15, 'Value 22': 16, 'Value 3': 17, 'Value 4': 18, 'Value 5': 19, 'Value 6': 20, 'Value 7': 21, 'Value 8': 22, 'Value 9': 23}), ('Variant index', 175, {'1.0': 1, '10.0': 2, '100.0': 3, '103.0': 4, '104.0': 5, '107.0': 6, '109.0': 7, '11.0': 8, '110.0': 9, '112.0': 10, '113.0': 11, '114.0': 12, '115.0': 13, '117.0': 14, '118.0': 15, '12.0': 16, '120.0': 17, '122.0': 18, '123.0': 19, '124.0': 20, '125.0': 21, '126.0': 22, '127.0': 23, '129.0': 24, '13.0': 25, '130.0': 26, '131.0': 27, '134.0': 28, '135.0': 29, '137.0': 30, '138.0': 31, '139.0': 32, '14.0': 33, '140.0': 34, '141.0': 35, '143.0': 36, '145.0': 37, '147.0': 38, '149.0': 39, '15.0': 40, '150.0': 41, '151.0': 42, '152.0': 43, '153.0': 44, '154.0': 45, '155.0': 46, '156.0': 47, '157.0': 48, '158.0': 49, '16.0': 50, '162.0': 51, '163.0': 52, '164.0': 53, '165.0': 54, '167.0': 55, '168.0': 56, '169.0': 57, '17.0': 58, '170.0': 59, '172.0': 60, '173.0': 61, '175.0': 62, '176.0': 63, '179.0': 64, '18.0': 65, '180.0': 66, '181.0': 67, '182.0': 68, '183.0': 69, '188.0': 70, '19.0': 71, '192.0': 72, '193.0': 73, '194.0': 74, '195.0': 75, '197.0': 76, '199.0': 77, '2.0': 78, '20.0': 79, '202.0': 80, '203.0': 81, '204.0': 82, '205.0': 83, '207.0': 84, '208.0': 85, '21.0': 86, '211.0': 87, '212.0': 88, '214.0': 89, '217.0': 90, '22.0': 91, '220.0': 92, '222.0': 93, '225.0': 94, '23.0': 95, '24.0': 96, '25.0': 97, '26.0': 98, '27.0': 99, '28.0': 100, '29.0': 101, '3.0': 102, '30.0': 103, '31.0': 104, '32.0': 105, '33.0': 106, '34.0': 107, '35.0': 108, '36.0': 109, '37.0': 110, '38.0': 111, '39.0': 112, '4.0': 113, '40.0': 114, '41.0': 115, '42.0': 116, '43.0': 117, '44.0': 118, '45.0': 119, '46.0': 120, '47.0': 121, '48.0': 122, '49.0': 123, '5.0': 124, '50.0': 125, '51.0': 126, '52.0': 127, '53.0': 128, '54.0': 129, '55.0': 130, '56.0': 131, '57.0': 132, '58.0': 133, '59.0': 134, '6.0': 135, '60.0': 136, '61.0': 137, '62.0': 138, '63.0': 139, '64.0': 140, '65.0': 141, '66.0': 142, '67.0': 143, '68.0': 144, '69.0': 145, '7.0': 146, '70.0': 147, '71.0': 148, '72.0': 149, '73.0': 150, '74.0': 151, '75.0': 152, '76.0': 153, '77.0': 154, '78.0': 155, '79.0': 156, '8.0': 157, '81.0': 158, '83.0': 159, '84.0': 160, '85.0': 161, '86.0': 162, '87.0': 163, '88.0': 164, '89.0': 165, '9.0': 166, '90.0': 167, '91.0': 168, '93.0': 169, '94.0': 170, '95.0': 171, '97.0': 172, '99.0': 173, nan: 174}), ('seriousness', 3, {'EOS': 1, 'Value 1': 2}), ('customer', 361, {'EOS': 1, 'Value 1': 2, 'Value 10': 3, 'Value 100': 4, 'Value 101': 5, 'Value 102': 6, 'Value 103': 7, 'Value 104': 8, 'Value 105': 9, 'Value 106': 10, 'Value 107': 11, 'Value 108': 12, 'Value 11': 13, 'Value 110': 14, 'Value 111': 15, 'Value 112': 16, 'Value 113': 17, 'Value 114': 18, 'Value 115': 19, 'Value 116': 20, 'Value 117': 21, 'Value 118': 22, 'Value 119': 23, 'Value 12': 24, 'Value 120': 25, 'Value 121': 26, 'Value 122': 27, 'Value 123': 28, 'Value 124': 29, 'Value 125': 30, 'Value 126': 31, 'Value 127': 32, 'Value 129': 33, 'Value 13': 34, 'Value 131': 35, 'Value 132': 36, 'Value 133': 37, 'Value 134': 38, 'Value 135': 39, 'Value 136': 40, 'Value 137': 41, 'Value 138': 42, 'Value 139': 43, 'Value 14': 44, 'Value 140': 45, 'Value 142': 46, 'Value 143': 47, 'Value 144': 48, 'Value 145': 49, 'Value 146': 50, 'Value 147': 51, 'Value 148': 52, 'Value 149': 53, 'Value 15': 54, 'Value 150': 55, 'Value 151': 56, 'Value 152': 57, 'Value 153': 58, 'Value 154': 59, 'Value 155': 60, 'Value 156': 61, 'Value 157': 62, 'Value 158': 63, 'Value 16': 64, 'Value 160': 65, 'Value 161': 66, 'Value 162': 67, 'Value 163': 68, 'Value 164': 69, 'Value 165': 70, 'Value 166': 71, 'Value 167': 72, 'Value 168': 73, 'Value 169': 74, 'Value 17': 75, 'Value 171': 76, 'Value 172': 77, 'Value 173': 78, 'Value 174': 79, 'Value 175': 80, 'Value 176': 81, 'Value 177': 82, 'Value 178': 83, 'Value 179': 84, 'Value 18': 85, 'Value 180': 86, 'Value 181': 87, 'Value 182': 88, 'Value 183': 89, 'Value 184': 90, 'Value 185': 91, 'Value 186': 92, 'Value 187': 93, 'Value 188': 94, 'Value 189': 95, 'Value 19': 96, 'Value 190': 97, 'Value 191': 98, 'Value 192': 99, 'Value 193': 100, 'Value 194': 101, 'Value 195': 102, 'Value 196': 103, 'Value 197': 104, 'Value 198': 105, 'Value 199': 106, 'Value 2': 107, 'Value 20': 108, 'Value 200': 109, 'Value 201': 110, 'Value 202': 111, 'Value 203': 112, 'Value 204': 113, 'Value 205': 114, 'Value 206': 115, 'Value 207': 116, 'Value 208': 117, 'Value 209': 118, 'Value 21': 119, 'Value 210': 120, 'Value 211': 121, 'Value 213': 122, 'Value 214': 123, 'Value 215': 124, 'Value 216': 125, 'Value 217': 126, 'Value 218': 127, 'Value 219': 128, 'Value 22': 129, 'Value 220': 130, 'Value 221': 131, 'Value 222': 132, 'Value 223': 133, 'Value 224': 134, 'Value 225': 135, 'Value 226': 136, 'Value 227': 137, 'Value 228': 138, 'Value 229': 139, 'Value 23': 140, 'Value 230': 141, 'Value 231': 142, 'Value 232': 143, 'Value 233': 144, 'Value 234': 145, 'Value 235': 146, 'Value 236': 147, 'Value 237': 148, 'Value 238': 149, 'Value 239': 150, 'Value 24': 151, 'Value 240': 152, 'Value 241': 153, 'Value 242': 154, 'Value 243': 155, 'Value 244': 156, 'Value 245': 157, 'Value 246': 158, 'Value 247': 159, 'Value 248': 160, 'Value 249': 161, 'Value 25': 162, 'Value 250': 163, 'Value 251': 164, 'Value 252': 165, 'Value 253': 166, 'Value 254': 167, 'Value 255': 168, 'Value 256': 169, 'Value 258': 170, 'Value 259': 171, 'Value 26': 172, 'Value 260': 173, 'Value 261': 174, 'Value 262': 175, 'Value 263': 176, 'Value 264': 177, 'Value 265': 178, 'Value 266': 179, 'Value 267': 180, 'Value 269': 181, 'Value 27': 182, 'Value 271': 183, 'Value 272': 184, 'Value 273': 185, 'Value 274': 186, 'Value 275': 187, 'Value 276': 188, 'Value 277': 189, 'Value 278': 190, 'Value 279': 191, 'Value 28': 192, 'Value 280': 193, 'Value 281': 194, 'Value 282': 195, 'Value 283': 196, 'Value 284': 197, 'Value 285': 198, 'Value 286': 199, 'Value 287': 200, 'Value 288': 201, 'Value 289': 202, 'Value 29': 203, 'Value 292': 204, 'Value 293': 205, 'Value 294': 206, 'Value 296': 207, 'Value 297': 208, 'Value 298': 209, 'Value 299': 210, 'Value 3': 211, 'Value 30': 212, 'Value 300': 213, 'Value 301': 214, 'Value 302': 215, 'Value 303': 216, 'Value 304': 217, 'Value 305': 218, 'Value 306': 219, 'Value 307': 220, 'Value 308': 221, 'Value 309': 222, 'Value 31': 223, 'Value 310': 224, 'Value 311': 225, 'Value 312': 226, 'Value 313': 227, 'Value 314': 228, 'Value 315': 229, 'Value 316': 230, 'Value 317': 231, 'Value 318': 232, 'Value 319': 233, 'Value 32': 234, 'Value 320': 235, 'Value 321': 236, 'Value 322': 237, 'Value 323': 238, 'Value 324': 239, 'Value 325': 240, 'Value 326': 241, 'Value 327': 242, 'Value 328': 243, 'Value 329': 244, 'Value 33': 245, 'Value 331': 246, 'Value 332': 247, 'Value 333': 248, 'Value 334': 249, 'Value 335': 250, 'Value 336': 251, 'Value 337': 252, 'Value 338': 253, 'Value 339': 254, 'Value 34': 255, 'Value 340': 256, 'Value 342': 257, 'Value 343': 258, 'Value 344': 259, 'Value 345': 260, 'Value 346': 261, 'Value 348': 262, 'Value 349': 263, 'Value 35': 264, 'Value 350': 265, 'Value 351': 266, 'Value 352': 267, 'Value 353': 268, 'Value 356': 269, 'Value 357': 270, 'Value 36': 271, 'Value 362': 272, 'Value 363': 273, 'Value 364': 274, 'Value 365': 275, 'Value 366': 276, 'Value 368': 277, 'Value 369': 278, 'Value 37': 279, 'Value 370': 280, 'Value 374': 281, 'Value 375': 282, 'Value 376': 283, 'Value 377': 284, 'Value 379': 285, 'Value 38': 286, 'Value 380': 287, 'Value 383': 288, 'Value 384': 289, 'Value 386': 290, 'Value 388': 291, 'Value 389': 292, 'Value 39': 293, 'Value 390': 294, 'Value 393': 295, 'Value 396': 296, 'Value 4': 297, 'Value 40': 298, 'Value 41': 299, 'Value 42': 300, 'Value 43': 301, 'Value 44': 302, 'Value 45': 303, 'Value 46': 304, 'Value 47': 305, 'Value 48': 306, 'Value 49': 307, 'Value 5': 308, 'Value 50': 309, 'Value 51': 310, 'Value 52': 311, 'Value 53': 312, 'Value 54': 313, 'Value 55': 314, 'Value 56': 315, 'Value 57': 316, 'Value 58': 317, 'Value 59': 318, 'Value 6': 319, 'Value 60': 320, 'Value 61': 321, 'Value 62': 322, 'Value 63': 323, 'Value 64': 324, 'Value 65': 325, 'Value 66': 326, 'Value 67': 327, 'Value 68': 328, 'Value 69': 329, 'Value 7': 330, 'Value 70': 331, 'Value 71': 332, 'Value 72': 333, 'Value 73': 334, 'Value 74': 335, 'Value 75': 336, 'Value 76': 337, 'Value 77': 338, 'Value 78': 339, 'Value 79': 340, 'Value 8': 341, 'Value 80': 342, 'Value 81': 343, 'Value 82': 344, 'Value 83': 345, 'Value 85': 346, 'Value 86': 347, 'Value 87': 348, 'Value 88': 349, 'Value 89': 350, 'Value 9': 351, 'Value 90': 352, 'Value 91': 353, 'Value 92': 354, 'Value 93': 355, 'Value 94': 356, 'Value 96': 357, 'Value 97': 358, 'Value 98': 359, 'Value 99': 360}), ('product', 23, {'EOS': 1, 'Value 1': 2, 'Value 10': 3, 'Value 11': 4, 'Value 12': 5, 'Value 13': 6, 'Value 14': 7, 'Value 15': 8, 'Value 16': 9, 'Value 17': 10, 'Value 18': 11, 'Value 19': 12, 'Value 2': 13, 'Value 20': 14, 'Value 21': 15, 'Value 3': 16, 'Value 4': 17, 'Value 5': 18, 'Value 6': 19, 'Value 7': 20, 'Value 8': 21, 'Value 9': 22}), ('responsible_section', 9, {'EOS': 1, 'Value 1': 2, 'Value 2': 3, 'Value 3': 4, 'Value 4': 5, 'Value 5': 6, 'Value 6': 7, 'Value 7': 8}), ('seriousness_2', 6, {'EOS': 1, 'Value 1': 2, 'Value 2': 3, 'Value 3': 4, 'Value 4': 5}), ('service_level', 6, {'EOS': 1, 'Value 1': 2, 'Value 2': 3, 'Value 3': 4, 'Value 4': 5}), ('service_type', 6, {'EOS': 1, 'Value 1': 2, 'Value 2': 3, 'Value 3': 4, 'Value 4': 5}), ('support_section', 8, {'EOS': 1, 'Value 1': 2, 'Value 2': 3, 'Value 3': 4, 'Value 4': 5, 'Value 5': 6, 'Value 6': 7}), ('workgroup', 6, {'EOS': 1, 'Value 1': 2, 'Value 2': 3, 'Value 3': 4, 'Value 4': 5})], [('case_elapsed_time', 1, {}), ('event_elapsed_time', 1, {}), ('day_in_week', 1, {}), ('seconds_in_day', 1, {})])\n",
      "Encoder input features:  [['Activity', 'Resource', 'Variant index', 'seriousness', 'customer', 'product', 'responsible_section', 'seriousness_2', 'service_level', 'service_type', 'support_section', 'workgroup'], ['case_elapsed_time', 'event_elapsed_time', 'day_in_week', 'seconds_in_day']]\n",
      "Decoder input+output features:  [['Activity', 'Resource', 'Variant index', 'seriousness', 'customer', 'product', 'responsible_section', 'seriousness_2', 'service_level', 'service_type', 'support_section', 'workgroup'], ['case_elapsed_time', 'event_elapsed_time', 'day_in_week', 'seconds_in_day']]\n",
      "\n",
      "\n",
      "Sequence length of decoder output:  4\n",
      "\n",
      "\n",
      "Cells hidden size:  128\n",
      "Number of LSTM layer:  2\n",
      "Dropout rate:  0.1\n",
      "\n",
      "\n",
      "Encoder number of labels for each input feature (categorical, numerical):  [[16, 24, 175, 3, 361, 23, 9, 6, 6, 6, 8, 6], [1, 1, 1, 1]]\n",
      "Encoder indices of tensors in dataset used as input:  [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], [0, 1, 2, 3]]\n",
      "Embeddings encoder:  ModuleList(\n",
      "  (0): Embedding(16, 8)\n",
      "  (1): Embedding(24, 9)\n",
      "  (2): Embedding(175, 29)\n",
      "  (3): Embedding(3, 3)\n",
      "  (4): Embedding(361, 43)\n",
      "  (5): Embedding(23, 9)\n",
      "  (6): Embedding(9, 5)\n",
      "  (7-9): 3 x Embedding(6, 4)\n",
      "  (10): Embedding(8, 5)\n",
      "  (11): Embedding(6, 4)\n",
      ")\n",
      "Total embedding feature size encoder:  127\n",
      "Total numerical feature size encoder:  4\n",
      "Input feature size encoder:  131\n",
      "Encoder initialized! \n",
      "\n",
      "Decoder label values size for each categorical input feature:  [16, 24, 175, 3, 361, 23, 9, 6, 6, 6, 8, 6]\n",
      "Decoder label values size for each numerical input feature:  [1, 1, 1, 1]\n",
      "Decoder indices of tensors in dataset used as input:  [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], [0, 1, 2, 3]]\n",
      "Embeddings decoder:  ModuleList(\n",
      "  (0): Embedding(16, 8)\n",
      "  (1): Embedding(24, 9)\n",
      "  (2): Embedding(175, 29)\n",
      "  (3): Embedding(3, 3)\n",
      "  (4): Embedding(361, 43)\n",
      "  (5): Embedding(23, 9)\n",
      "  (6): Embedding(9, 5)\n",
      "  (7-9): 3 x Embedding(6, 4)\n",
      "  (10): Embedding(8, 5)\n",
      "  (11): Embedding(6, 4)\n",
      ")\n",
      "Total embedding feature size decoder:  127\n",
      "Total numerical feature size decoder:  4\n",
      "Input feature size decoder:  131\n",
      "Output feature list of dicts (featue name, feature output size) of decoder:  [{'Activity': 16, 'Resource': 24, 'Variant index': 175, 'seriousness': 3, 'customer': 361, 'product': 23, 'responsible_section': 9, 'seriousness_2': 6, 'service_level': 6, 'service_type': 6, 'support_section': 8, 'workgroup': 6}, {'case_elapsed_time': 1, 'event_elapsed_time': 1, 'day_in_week': 1, 'seconds_in_day': 1}]\n",
      "Decoder initialized! \n",
      "\n",
      "Output feature list of dicts (featue name, tensor index in dataset) of decoder:  [{'Activity': 0, 'Resource': 1, 'Variant index': 2, 'seriousness': 3, 'customer': 4, 'product': 5, 'responsible_section': 6, 'seriousness_2': 7, 'service_level': 8, 'service_type': 9, 'support_section': 10, 'workgroup': 11}, {'case_elapsed_time': 0, 'event_elapsed_time': 1, 'day_in_week': 2, 'seconds_in_day': 3}]\n"
     ]
    }
   ],
   "source": [
    "import model.dropout_uncertainty_enc_dec_LSTM.dropout_uncertainty_model\n",
    "importlib.reload(model.dropout_uncertainty_enc_dec_LSTM.dropout_uncertainty_model)\n",
    "from model.dropout_uncertainty_enc_dec_LSTM.dropout_uncertainty_model import DropoutUncertaintyEncoderDecoderLSTM\n",
    "\n",
    "# Prediction decoder output sequence length\n",
    "seq_len_pred = 4\n",
    "\n",
    "# Size hidden layer\n",
    "hidden_size = 128\n",
    "\n",
    "# Number of cells\n",
    "num_layers = 2\n",
    "\n",
    "# Fixed Dropout probability \n",
    "dropout = 0.1\n",
    "\n",
    "# Encoder Decoder model initialization\n",
    "model = DropoutUncertaintyEncoderDecoderLSTM(data_set_categories=bpic_17_all_categories,\n",
    "                                             enc_feat=enc_feat,\n",
    "                                             dec_feat=dec_feat,\n",
    "                                             seq_len_pred=seq_len_pred,\n",
    "                                             hidden_size=hidden_size,\n",
    "                                             num_layers=num_layers,\n",
    "                                             dropout=dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Object Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T22:34:59.676816Z",
     "iopub.status.busy": "2025-02-14T22:34:59.676729Z",
     "iopub.status.idle": "2025-02-14T22:34:59.687741Z",
     "shell.execute_reply": "2025-02-14T22:34:59.687519Z"
    }
   },
   "outputs": [],
   "source": [
    "import loss.losses\n",
    "importlib.reload(loss.losses)\n",
    "from loss.losses import Loss\n",
    "\n",
    "loss_obj = Loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T22:34:59.688811Z",
     "iopub.status.busy": "2025-02-14T22:34:59.688659Z",
     "iopub.status.idle": "2025-02-16T11:38:25.278943Z",
     "shell.execute_reply": "2025-02-16T11:38:25.278599Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cpu\n",
      "Model:  DropoutUncertaintyEncoderDecoderLSTM(\n",
      "  (embeddings_enc): ModuleList(\n",
      "    (0): Embedding(16, 8)\n",
      "    (1): Embedding(24, 9)\n",
      "    (2): Embedding(175, 29)\n",
      "    (3): Embedding(3, 3)\n",
      "    (4): Embedding(361, 43)\n",
      "    (5): Embedding(23, 9)\n",
      "    (6): Embedding(9, 5)\n",
      "    (7-9): 3 x Embedding(6, 4)\n",
      "    (10): Embedding(8, 5)\n",
      "    (11): Embedding(6, 4)\n",
      "  )\n",
      "  (encoder): DropoutUncertaintyLSTMEncoder(\n",
      "    (embeddings): ModuleList(\n",
      "      (0): Embedding(16, 8)\n",
      "      (1): Embedding(24, 9)\n",
      "      (2): Embedding(175, 29)\n",
      "      (3): Embedding(3, 3)\n",
      "      (4): Embedding(361, 43)\n",
      "      (5): Embedding(23, 9)\n",
      "      (6): Embedding(9, 5)\n",
      "      (7-9): 3 x Embedding(6, 4)\n",
      "      (10): Embedding(8, 5)\n",
      "      (11): Embedding(6, 4)\n",
      "    )\n",
      "    (first_layer): DropoutUncertaintyLSTMCell(\n",
      "      (Wi): Linear(in_features=131, out_features=128, bias=True)\n",
      "      (Ui): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (Wf): Linear(in_features=131, out_features=128, bias=True)\n",
      "      (Uf): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (Wc): Linear(in_features=131, out_features=128, bias=True)\n",
      "      (Uc): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (Wo): Linear(in_features=131, out_features=128, bias=True)\n",
      "      (Uo): Linear(in_features=128, out_features=128, bias=True)\n",
      "    )\n",
      "    (hidden_layers): ModuleList(\n",
      "      (0): DropoutUncertaintyLSTMCell(\n",
      "        (Wi): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (Ui): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (Wf): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (Uf): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (Wc): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (Uc): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (Wo): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (Uo): Linear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (embeddings_dec): ModuleList(\n",
      "    (0): Embedding(16, 8)\n",
      "    (1): Embedding(24, 9)\n",
      "    (2): Embedding(175, 29)\n",
      "    (3): Embedding(3, 3)\n",
      "    (4): Embedding(361, 43)\n",
      "    (5): Embedding(23, 9)\n",
      "    (6): Embedding(9, 5)\n",
      "    (7-9): 3 x Embedding(6, 4)\n",
      "    (10): Embedding(8, 5)\n",
      "    (11): Embedding(6, 4)\n",
      "  )\n",
      "  (decoder): DropoutUncertaintyLSTMDecoder(\n",
      "    (embeddings): ModuleList(\n",
      "      (0): Embedding(16, 8)\n",
      "      (1): Embedding(24, 9)\n",
      "      (2): Embedding(175, 29)\n",
      "      (3): Embedding(3, 3)\n",
      "      (4): Embedding(361, 43)\n",
      "      (5): Embedding(23, 9)\n",
      "      (6): Embedding(9, 5)\n",
      "      (7-9): 3 x Embedding(6, 4)\n",
      "      (10): Embedding(8, 5)\n",
      "      (11): Embedding(6, 4)\n",
      "    )\n",
      "    (first_layer): DropoutUncertaintyLSTMCell(\n",
      "      (Wi): Linear(in_features=131, out_features=128, bias=True)\n",
      "      (Ui): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (Wf): Linear(in_features=131, out_features=128, bias=True)\n",
      "      (Uf): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (Wc): Linear(in_features=131, out_features=128, bias=True)\n",
      "      (Uc): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (Wo): Linear(in_features=131, out_features=128, bias=True)\n",
      "      (Uo): Linear(in_features=128, out_features=128, bias=True)\n",
      "    )\n",
      "    (hidden_layers): ModuleList(\n",
      "      (0): DropoutUncertaintyLSTMCell(\n",
      "        (Wi): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (Ui): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (Wf): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (Uf): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (Wc): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (Uc): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (Wo): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (Uo): Linear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (output_layers): ModuleDict(\n",
      "      (Activity_mean): Linear(in_features=128, out_features=16, bias=True)\n",
      "      (Activity_var): Linear(in_features=128, out_features=16, bias=True)\n",
      "      (Resource_mean): Linear(in_features=128, out_features=24, bias=True)\n",
      "      (Resource_var): Linear(in_features=128, out_features=24, bias=True)\n",
      "      (Variant index_mean): Linear(in_features=128, out_features=175, bias=True)\n",
      "      (Variant index_var): Linear(in_features=128, out_features=175, bias=True)\n",
      "      (seriousness_mean): Linear(in_features=128, out_features=3, bias=True)\n",
      "      (seriousness_var): Linear(in_features=128, out_features=3, bias=True)\n",
      "      (customer_mean): Linear(in_features=128, out_features=361, bias=True)\n",
      "      (customer_var): Linear(in_features=128, out_features=361, bias=True)\n",
      "      (product_mean): Linear(in_features=128, out_features=23, bias=True)\n",
      "      (product_var): Linear(in_features=128, out_features=23, bias=True)\n",
      "      (responsible_section_mean): Linear(in_features=128, out_features=9, bias=True)\n",
      "      (responsible_section_var): Linear(in_features=128, out_features=9, bias=True)\n",
      "      (seriousness_2_mean): Linear(in_features=128, out_features=6, bias=True)\n",
      "      (seriousness_2_var): Linear(in_features=128, out_features=6, bias=True)\n",
      "      (service_level_mean): Linear(in_features=128, out_features=6, bias=True)\n",
      "      (service_level_var): Linear(in_features=128, out_features=6, bias=True)\n",
      "      (service_type_mean): Linear(in_features=128, out_features=6, bias=True)\n",
      "      (service_type_var): Linear(in_features=128, out_features=6, bias=True)\n",
      "      (support_section_mean): Linear(in_features=128, out_features=8, bias=True)\n",
      "      (support_section_var): Linear(in_features=128, out_features=8, bias=True)\n",
      "      (workgroup_mean): Linear(in_features=128, out_features=6, bias=True)\n",
      "      (workgroup_var): Linear(in_features=128, out_features=6, bias=True)\n",
      "      (case_elapsed_time_mean): Linear(in_features=128, out_features=1, bias=True)\n",
      "      (case_elapsed_time_var): Linear(in_features=128, out_features=1, bias=True)\n",
      "      (event_elapsed_time_mean): Linear(in_features=128, out_features=1, bias=True)\n",
      "      (event_elapsed_time_var): Linear(in_features=128, out_features=1, bias=True)\n",
      "      (day_in_week_mean): Linear(in_features=128, out_features=1, bias=True)\n",
      "      (day_in_week_var): Linear(in_features=128, out_features=1, bias=True)\n",
      "      (seconds_in_day_mean): Linear(in_features=128, out_features=1, bias=True)\n",
      "      (seconds_in_day_var): Linear(in_features=128, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Train Dataset:  <event_log_loader.new_event_log_loader.EventLogDataset object at 0x143d30ec0>\n",
      "Validation Dataset:  <event_log_loader.new_event_log_loader.EventLogDataset object at 0x143d45e50>\n",
      "Loss object for method calling:  <loss.losses.Loss object at 0x143d32510>\n",
      "Num. feautures that follow log-normal PDF:  []\n",
      "regularization:  0.001953125\n",
      "Optimizer:  Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    decoupled_weight_decay: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 1e-06\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Scheduler:  <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x153010050>\n",
      "Epochs:  200\n",
      "Mini baches:  256\n",
      "Shuffle batched dataset:  True\n",
      "Teacher forcing ratio:  0.8\n",
      "Use GradNorm:  False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c146192113de41d183589a2a3583adf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leonurny/.local/share/virtualenvs/Probabilistic_Suffix_Prediction_U-ED-LSTM_-32bEAP25/lib/python3.13/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], Learning Rate: 1e-06, Teacher forcing ratio: 0.8\n",
      "Training: Avg Attenuated Training Loss: 40.6120\n",
      "Validation: Avg Standard Validation Loss: 36.3517\n",
      "Validation: Avg Attenuated Validation Loss: 39.5094\n",
      "Validation Loss for Scheduler: 36.3517\n",
      "saving model\n",
      "Epoch [2/200], Learning Rate: 1e-06, Teacher forcing ratio: 0.8\n",
      "Training: Avg Attenuated Training Loss: 40.5923\n",
      "Validation: Avg Standard Validation Loss: 36.4156\n",
      "Validation: Avg Attenuated Validation Loss: 39.5277\n",
      "Validation Loss for Scheduler: 36.4156\n",
      "saving model\n",
      "Epoch [3/200], Learning Rate: 1e-06, Teacher forcing ratio: 0.8\n",
      "Training: Avg Attenuated Training Loss: 40.5627\n",
      "Validation: Avg Standard Validation Loss: 36.2786\n",
      "Validation: Avg Attenuated Validation Loss: 39.4604\n",
      "Validation Loss for Scheduler: 36.2786\n",
      "saving model\n",
      "Epoch [4/200], Learning Rate: 1e-06, Teacher forcing ratio: 0.8\n",
      "Training: Avg Attenuated Training Loss: 40.5412\n",
      "Validation: Avg Standard Validation Loss: 36.3527\n",
      "Validation: Avg Attenuated Validation Loss: 39.4702\n",
      "Validation Loss for Scheduler: 36.3527\n",
      "saving model\n",
      "Epoch [5/200], Learning Rate: 1e-06, Teacher forcing ratio: 0.8\n",
      "Training: Avg Attenuated Training Loss: 40.5071\n",
      "Validation: Avg Standard Validation Loss: 36.3746\n",
      "Validation: Avg Attenuated Validation Loss: 39.4888\n",
      "Validation Loss for Scheduler: 36.3746\n",
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x130277e20>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/leonurny/.local/share/virtualenvs/Probabilistic_Suffix_Prediction_U-ED-LSTM_-32bEAP25/lib/python3.13/site-packages/torch/utils/data/dataloader.py\", line 1663, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Users/leonurny/.local/share/virtualenvs/Probabilistic_Suffix_Prediction_U-ED-LSTM_-32bEAP25/lib/python3.13/site-packages/torch/utils/data/dataloader.py\", line 1627, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/Users/leonurny/.pyenv/versions/3.13.1/lib/python3.13/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/Users/leonurny/.pyenv/versions/3.13.1/lib/python3.13/multiprocessing/popen_fork.py\", line 41, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/Users/leonurny/.pyenv/versions/3.13.1/lib/python3.13/multiprocessing/connection.py\", line 1148, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/Users/leonurny/.pyenv/versions/3.13.1/lib/python3.13/selectors.py\", line 398, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "  File \"/Users/leonurny/.local/share/virtualenvs/Probabilistic_Suffix_Prediction_U-ED-LSTM_-32bEAP25/lib/python3.13/site-packages/torch/utils/data/_utils/signal_handling.py\", line 73, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 13544) is killed by signal: Abort trap: 6. \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 66\u001b[39m\n\u001b[32m     51\u001b[39m trainer = Trainer(device=device,\n\u001b[32m     52\u001b[39m                   model=model,\n\u001b[32m     53\u001b[39m                   data_train=BPIC_17_train_dataset,\n\u001b[32m   (...)\u001b[39m\u001b[32m     61\u001b[39m                   save_model_n_th_epoch = \u001b[32m1\u001b[39m,\n\u001b[32m     62\u001b[39m                   saving_path = \u001b[33m'\u001b[39m\u001b[33mHelpdesk_full_no_grad_norm_new_1.pkl\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# Train the model:\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m train_attenuated_losses, val_losses, val_attenuated_losses = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Robustness-in-suffix-prediction/src/notebooks/training_variational_dropout/BPIC17/../../../trainer/trainer.py:186\u001b[39m, in \u001b[36mTrainer.train_model\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    182\u001b[39m     cat_losses_dict, num_losses_dict = all_losses_dict\n\u001b[32m    184\u001b[39m \u001b[38;5;66;03m# Standard Training:    \u001b[39;00m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m     all_losses_dict, loss_value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprefixes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprefixes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[43m=\u001b[49m\u001b[43msuffixes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    187\u001b[39m     cat_losses_dict, num_losses_dict = all_losses_dict\n\u001b[32m    189\u001b[39m \u001b[38;5;66;03m# Accumulate the categorical losses\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Robustness-in-suffix-prediction/src/notebooks/training_variational_dropout/BPIC17/../../../trainer/trainer.py:362\u001b[39m, in \u001b[36mTrainer.train_epoch\u001b[39m\u001b[34m(self, prefixes, suffixes)\u001b[39m\n\u001b[32m    360\u001b[39m target_cat = cat_suffixes_dict[feature_name] \u001b[38;5;66;03m# dim: batch size x seq len\u001b[39;00m\n\u001b[32m    361\u001b[39m \u001b[38;5;66;03m# Loss caluclation\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m362\u001b[39m loss_cat = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloss_obj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloss_attenuation_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_logits\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmean_cat_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_logvars\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvar_cat_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget_cat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlong\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (feature_name \u001b[38;5;129;01min\u001b[39;00m cat_loss_dict):\n\u001b[32m    365\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mFeature is already in output dict\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Robustness-in-suffix-prediction/src/notebooks/training_variational_dropout/BPIC17/../../../loss/losses.py:169\u001b[39m, in \u001b[36mLoss.loss_attenuation_cross_entropy\u001b[39m\u001b[34m(self, pred_logits, pred_logvars, T, targets)\u001b[39m\n\u001b[32m    166\u001b[39m     pred_logits_std_noise = pred_logits_std_noise.permute(\u001b[32m1\u001b[39m,\u001b[32m2\u001b[39m,\u001b[32m0\u001b[39m)\n\u001b[32m    168\u001b[39m     \u001b[38;5;66;03m# CEL of gaussian distributed unaries and target\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m     ce_loss = \u001b[43mCEL\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mpred_logits_std_noise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    171\u001b[39m     L += ce_loss\n\u001b[32m    173\u001b[39m L = (\u001b[32m1\u001b[39m/T) * L\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/Probabilistic_Suffix_Prediction_U-ED-LSTM_-32bEAP25/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/Probabilistic_Suffix_Prediction_U-ED-LSTM_-32bEAP25/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/Probabilistic_Suffix_Prediction_U-ED-LSTM_-32bEAP25/lib/python3.13/site-packages/torch/nn/modules/loss.py:1297\u001b[39m, in \u001b[36mCrossEntropyLoss.forward\u001b[39m\u001b[34m(self, input, target)\u001b[39m\n\u001b[32m   1296\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) -> Tensor:\n\u001b[32m-> \u001b[39m\u001b[32m1297\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1298\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1299\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1300\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1301\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1302\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1303\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1304\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/Probabilistic_Suffix_Prediction_U-ED-LSTM_-32bEAP25/lib/python3.13/site-packages/torch/nn/functional.py:3494\u001b[39m, in \u001b[36mcross_entropy\u001b[39m\u001b[34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[39m\n\u001b[32m   3492\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3493\u001b[39m     reduction = _Reduction.legacy_get_string(size_average, reduce)\n\u001b[32m-> \u001b[39m\u001b[32m3494\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_nn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3495\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3496\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3497\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3498\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3499\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3500\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3501\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import trainer.trainer\n",
    "importlib.reload(trainer.trainer)\n",
    "from trainer.trainer import Trainer\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter(comment=\"Full_BPIC17_no_grad\")\n",
    "\n",
    "# device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Start learning rate\n",
    "learning_rate = 1e-6\n",
    "\n",
    "# Optimizer and Scheduler\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate, weight_decay=0)\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2, min_lr=1e-10)\n",
    "\n",
    "# Epochs\n",
    "num_epochs = 200\n",
    "\n",
    "# BATCHING does not work currntly with custom implementation\n",
    "batch_size = 256\n",
    "\n",
    "# lambda for L2 (weight, bias, dropout) regularization: According to formula: 1/2N\n",
    "regularization_term = 1.0/(2.0*batch_size)\n",
    "\n",
    "# shuffle data\n",
    "shuffle = True\n",
    "\n",
    "# Teacher forcing: Smaller 0.5 more target events are used for next event prediction.\n",
    "teacher_forcing_ratio = 0.8\n",
    "\n",
    "optimize_values = {\"regularization_term\":regularization_term,\n",
    "                   \"optimizer\":optimizer,\n",
    "                   \"scheduler\": scheduler,\n",
    "                   \"epochs\":num_epochs,\n",
    "                   \"mini_batches\":batch_size,\n",
    "                   \"shuffle\": shuffle,\n",
    "                   \"teacher_forcing_ratio\":teacher_forcing_ratio,}\n",
    "\n",
    "suffix_data_split_value = 4\n",
    "\n",
    "# GradNorm parameter\n",
    "gradNorm = {\"use_gradnorm\":False}\n",
    "\n",
    "## Changed name because of good results of actual model\n",
    "\n",
    "trainer = Trainer(device=device,\n",
    "                  model=model,\n",
    "                  data_train=BPIC_17_train_dataset,\n",
    "                  data_val=BPIC_17_val_dataset,\n",
    "                  loss_obj=loss_obj,\n",
    "                  optimize_values=optimize_values,\n",
    "                  log_normal_loss_num_feature=[],\n",
    "                  suffix_data_split_value=suffix_data_split_value,\n",
    "                  writer=writer,\n",
    "                  gradnorm_values=gradNorm,\n",
    "                  save_model_n_th_epoch = 1,\n",
    "                  saving_path = 'Helpdesk_full_no_grad_norm_new_1.pkl')\n",
    "                  \n",
    "\n",
    "# Train the model:\n",
    "train_attenuated_losses, val_losses, val_attenuated_losses = trainer.train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T11:38:25.282167Z",
     "iopub.status.busy": "2025-02-16T11:38:25.281655Z",
     "iopub.status.idle": "2025-02-16T11:38:25.528248Z",
     "shell.execute_reply": "2025-02-16T11:38:25.527891Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# After training is finished, plot the loss curves\n",
    "plt.plot(range(1, num_epochs+1), train_attenuated_losses, label='Training Attenuated Loss', color='blue')\n",
    "plt.plot(range(1, num_epochs+1), val_losses, label='Validation Loss', color='orange')\n",
    "plt.plot(range(1, num_epochs+1), val_attenuated_losses, label='Validation Attenuated Loss', color='green')\n",
    "# Labeling x and y axes\n",
    "plt.xlabel('Epochs', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "# Adding title\n",
    "plt.title('Training and Validation Loss Curve', fontsize=14)\n",
    "# Adding legend\n",
    "plt.legend()\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Probabilistic_Suffix_Prediction_U-ED-LSTM_-32bEAP25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "16231126389a4fc18582f6fc65619317": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_680a3aed9353436092161ddd6e3bbbfb",
       "max": 200,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_20fa79f2eee24c9ea6a4717080eaec45",
       "tabbable": null,
       "tooltip": null,
       "value": 200
      }
     },
     "20fa79f2eee24c9ea6a4717080eaec45": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "4cd34d65479c482e98fdf6f44d1166a1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5304a5dabe2344f8ba153be7b058a22c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6021cb9c1a1a4d3aab28f8bedc1cfd70": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_fc5787d40b1648a691004bab913ed4e8",
       "placeholder": "",
       "style": "IPY_MODEL_f7ecd9cdcf7144e19b06bc3006af281b",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     },
     "680a3aed9353436092161ddd6e3bbbfb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9a093bf694404b649375a9334600f45d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6021cb9c1a1a4d3aab28f8bedc1cfd70",
        "IPY_MODEL_16231126389a4fc18582f6fc65619317",
        "IPY_MODEL_d1c9ecb2673f43f596f2c1eca79032ae"
       ],
       "layout": "IPY_MODEL_f92e14faa71447d4b2a004b9a2a6a5e9",
       "tabbable": null,
       "tooltip": null
      }
     },
     "d1c9ecb2673f43f596f2c1eca79032ae": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5304a5dabe2344f8ba153be7b058a22c",
       "placeholder": "",
       "style": "IPY_MODEL_4cd34d65479c482e98fdf6f44d1166a1",
       "tabbable": null,
       "tooltip": null,
       "value": "200/200[37:03:24&lt;00:00,648.51s/it]"
      }
     },
     "f7ecd9cdcf7144e19b06bc3006af281b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f92e14faa71447d4b2a004b9a2a6a5e9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fc5787d40b1648a691004bab913ed4e8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
