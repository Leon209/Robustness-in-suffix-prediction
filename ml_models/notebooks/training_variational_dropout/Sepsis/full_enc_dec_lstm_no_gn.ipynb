{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-12T17:12:18.773351Z",
     "iopub.status.busy": "2025-02-12T17:12:18.773191Z",
     "iopub.status.idle": "2025-02-12T17:12:19.480885Z",
     "shell.execute_reply": "2025-02-12T17:12:19.480578Z"
    }
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "sys.path.insert(1, '../..')\n",
    "sys.path.insert(2, '../../..')\n",
    "sys.path.insert(3, '../../../..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-12T17:12:19.482351Z",
     "iopub.status.busy": "2025-02-12T17:12:19.482215Z",
     "iopub.status.idle": "2025-02-12T17:12:20.003189Z",
     "shell.execute_reply": "2025-02-12T17:12:20.002910Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'event_log_loader.new_event_log_loader.EventLogDataset'>\n",
      "<class 'event_log_loader.new_event_log_loader.EventLogDataset'>\n"
     ]
    }
   ],
   "source": [
    "# Path to your pickle file (saved with torch.save)\n",
    "file_path_train = '../../../../encoded_data/sepsis/Sepsis_all_5_train.pkl'\n",
    "# Load the dataset using torch.load\n",
    "sepsis_train_dataset = torch.load(file_path_train, weights_only=False)\n",
    "# Check the type of the loaded dataset\n",
    "print(type(sepsis_train_dataset))  # Should output something like <class 'torch.utils.data.dataset.TensorDataset'>\n",
    "\n",
    "# Path to your pickle file (saved with torch.save)\n",
    "file_path_val = '../../../../encoded_data/sepsis/Sepsis_all_5_val.pkl'\n",
    "# Load the dataset using torch.load\n",
    "sepsis_val_dataset = torch.load(file_path_val, weights_only=False)\n",
    "# Check the type of the loaded dataset\n",
    "print(type(sepsis_val_dataset))  # Should output something like <class 'torch.utils.data.dataset.TensorDataset'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Data Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-12T17:12:20.004267Z",
     "iopub.status.busy": "2025-02-12T17:12:20.004119Z",
     "iopub.status.idle": "2025-02-12T17:12:20.006841Z",
     "shell.execute_reply": "2025-02-12T17:12:20.006635Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('concept:name', 18, {'Admission IC': 1, 'Admission NC': 2, 'CRP': 3, 'EOS': 4, 'ER Registration': 5, 'ER Sepsis Triage': 6, 'ER Triage': 7, 'IV Antibiotics': 8, 'IV Liquid': 9, 'LacticAcid': 10, 'Leucocytes': 11, 'Release A': 12, 'Release B': 13, 'Release C': 14, 'Release D': 15, 'Release E': 16, 'Return ER': 17}), ('InfectionSuspected', 5, {'EOS': 1, 'False': 2, 'True': 3, nan: 4}), ('org:group', 27, {'?': 1, 'A': 2, 'B': 3, 'C': 4, 'D': 5, 'E': 6, 'EOS': 7, 'F': 8, 'G': 9, 'H': 10, 'I': 11, 'J': 12, 'K': 13, 'L': 14, 'M': 15, 'N': 16, 'O': 17, 'P': 18, 'Q': 19, 'R': 20, 'S': 21, 'T': 22, 'U': 23, 'V': 24, 'W': 25, 'Y': 26}), ('DiagnosticBlood', 5, {'EOS': 1, 'False': 2, 'True': 3, nan: 4}), ('DisfuncOrg', 5, {'EOS': 1, 'False': 2, 'True': 3, nan: 4}), ('SIRSCritTachypnea', 5, {'EOS': 1, 'False': 2, 'True': 3, nan: 4}), ('Hypotensie', 5, {'EOS': 1, 'False': 2, 'True': 3, nan: 4}), ('SIRSCritHeartRate', 5, {'EOS': 1, 'False': 2, 'True': 3, nan: 4}), ('Infusion', 5, {'EOS': 1, 'False': 2, 'True': 3, nan: 4}), ('DiagnosticArtAstrup', 5, {'EOS': 1, 'False': 2, 'True': 3, nan: 4}), ('DiagnosticIC', 5, {'EOS': 1, 'False': 2, 'True': 3, nan: 4}), ('DiagnosticSputum', 5, {'EOS': 1, 'False': 2, 'True': 3, nan: 4}), ('DiagnosticLiquor', 5, {'EOS': 1, 'False': 2, 'True': 3, nan: 4}), ('DiagnosticOther', 5, {'EOS': 1, 'False': 2, 'True': 3, nan: 4}), ('SIRSCriteria2OrMore', 5, {'EOS': 1, 'False': 2, 'True': 3, nan: 4}), ('DiagnosticXthorax', 5, {'EOS': 1, 'False': 2, 'True': 3, nan: 4}), ('SIRSCritTemperature', 5, {'EOS': 1, 'False': 2, 'True': 3, nan: 4}), ('DiagnosticUrinaryCulture', 5, {'EOS': 1, 'False': 2, 'True': 3, nan: 4}), ('SIRSCritLeucos', 5, {'EOS': 1, 'False': 2, 'True': 3, nan: 4}), ('Oligurie', 5, {'EOS': 1, 'False': 2, 'True': 3, nan: 4}), ('DiagnosticLacticAcid', 5, {'EOS': 1, 'False': 2, 'True': 3, nan: 4}), ('lifecycle:transition', 3, {'EOS': 1, 'complete': 2}), ('Diagnose', 117, {'AA': 1, 'AC': 2, 'AD': 3, 'AE': 4, 'B': 5, 'BB': 6, 'BC': 7, 'BD': 8, 'C': 9, 'CA': 10, 'CB': 11, 'CC': 12, 'CD': 13, 'D': 14, 'DB': 15, 'DD': 16, 'DE': 17, 'E': 18, 'EA': 19, 'EC': 20, 'ED': 21, 'EE': 22, 'EOS': 23, 'F': 24, 'FA': 25, 'FC': 26, 'FD': 27, 'FE': 28, 'G': 29, 'GA': 30, 'GB': 31, 'GC': 32, 'GD': 33, 'GE': 34, 'H': 35, 'HA': 36, 'HB': 37, 'HC': 38, 'HD': 39, 'HE': 40, 'I': 41, 'IA': 42, 'IC': 43, 'J': 44, 'JC': 45, 'JE': 46, 'K': 47, 'KA': 48, 'KB': 49, 'KC': 50, 'KD': 51, 'L': 52, 'LA': 53, 'LB': 54, 'LC': 55, 'LD': 56, 'LE': 57, 'M': 58, 'MA': 59, 'MB': 60, 'MC': 61, 'MD': 62, 'ME': 63, 'N': 64, 'NB': 65, 'NC': 66, 'ND': 67, 'O': 68, 'OB': 69, 'OC': 70, 'OD': 71, 'OE': 72, 'P': 73, 'PC': 74, 'PD': 75, 'Q': 76, 'QB': 77, 'QD': 78, 'QE': 79, 'R': 80, 'RA': 81, 'RB': 82, 'RC': 83, 'RD': 84, 'S': 85, 'SA': 86, 'SB': 87, 'SD': 88, 'T': 89, 'TB': 90, 'U': 91, 'UA': 92, 'UC': 93, 'UD': 94, 'V': 95, 'VA': 96, 'VB': 97, 'VD': 98, 'W': 99, 'WA': 100, 'WB': 101, 'WC': 102, 'WD': 103, 'X': 104, 'XA': 105, 'XB': 106, 'XC': 107, 'XD': 108, 'Y': 109, 'YA': 110, 'YC': 111, 'Z': 112, 'ZA': 113, 'ZB': 114, 'ZD': 115, nan: 116}), ('Hypoxie', 5, {'EOS': 1, 'False': 2, 'True': 3, nan: 4}), ('DiagnosticUrinarySediment', 5, {'EOS': 1, 'False': 2, 'True': 3, nan: 4}), ('DiagnosticECG', 5, {'EOS': 1, 'False': 2, 'True': 3, nan: 4})]\n",
      "[('case_elapsed_time', 1, {}), ('event_elapsed_time', 1, {}), ('day_in_week', 1, {}), ('seconds_in_day', 1, {}), ('Age', 1, {}), ('Leucocytes', 1, {}), ('CRP', 1, {}), ('LacticAcid', 1, {})]\n",
      "Sepsis (5) Categorical feature: concept:name, Index position in categorical data list: 0\n",
      "Sepsis (5) Total Amount of Category labels: 18\n",
      "Sepsis (5) Categorical feature: InfectionSuspected, Index position in categorical data list: 1\n",
      "Sepsis (5) Total Amount of Category labels: 5\n",
      "Sepsis (5) Categorical feature: org:group, Index position in categorical data list: 2\n",
      "Sepsis (5) Total Amount of Category labels: 27\n",
      "Sepsis (5) Categorical feature: DiagnosticBlood, Index position in categorical data list: 3\n",
      "Sepsis (5) Total Amount of Category labels: 5\n",
      "Sepsis (5) Categorical feature: DisfuncOrg, Index position in categorical data list: 4\n",
      "Sepsis (5) Total Amount of Category labels: 5\n",
      "Sepsis (5) Categorical feature: SIRSCritTachypnea, Index position in categorical data list: 5\n",
      "Sepsis (5) Total Amount of Category labels: 5\n",
      "Sepsis (5) Categorical feature: Hypotensie, Index position in categorical data list: 6\n",
      "Sepsis (5) Total Amount of Category labels: 5\n",
      "Sepsis (5) Categorical feature: SIRSCritHeartRate, Index position in categorical data list: 7\n",
      "Sepsis (5) Total Amount of Category labels: 5\n",
      "Sepsis (5) Categorical feature: Infusion, Index position in categorical data list: 8\n",
      "Sepsis (5) Total Amount of Category labels: 5\n",
      "Sepsis (5) Categorical feature: DiagnosticArtAstrup, Index position in categorical data list: 9\n",
      "Sepsis (5) Total Amount of Category labels: 5\n",
      "Sepsis (5) Categorical feature: DiagnosticIC, Index position in categorical data list: 10\n",
      "Sepsis (5) Total Amount of Category labels: 5\n",
      "Sepsis (5) Categorical feature: DiagnosticSputum, Index position in categorical data list: 11\n",
      "Sepsis (5) Total Amount of Category labels: 5\n",
      "Sepsis (5) Categorical feature: DiagnosticLiquor, Index position in categorical data list: 12\n",
      "Sepsis (5) Total Amount of Category labels: 5\n",
      "Sepsis (5) Categorical feature: DiagnosticOther, Index position in categorical data list: 13\n",
      "Sepsis (5) Total Amount of Category labels: 5\n",
      "Sepsis (5) Categorical feature: SIRSCriteria2OrMore, Index position in categorical data list: 14\n",
      "Sepsis (5) Total Amount of Category labels: 5\n",
      "Sepsis (5) Categorical feature: DiagnosticXthorax, Index position in categorical data list: 15\n",
      "Sepsis (5) Total Amount of Category labels: 5\n",
      "Sepsis (5) Categorical feature: SIRSCritTemperature, Index position in categorical data list: 16\n",
      "Sepsis (5) Total Amount of Category labels: 5\n",
      "Sepsis (5) Categorical feature: DiagnosticUrinaryCulture, Index position in categorical data list: 17\n",
      "Sepsis (5) Total Amount of Category labels: 5\n",
      "Sepsis (5) Categorical feature: SIRSCritLeucos, Index position in categorical data list: 18\n",
      "Sepsis (5) Total Amount of Category labels: 5\n",
      "Sepsis (5) Categorical feature: Oligurie, Index position in categorical data list: 19\n",
      "Sepsis (5) Total Amount of Category labels: 5\n",
      "Sepsis (5) Categorical feature: DiagnosticLacticAcid, Index position in categorical data list: 20\n",
      "Sepsis (5) Total Amount of Category labels: 5\n",
      "Sepsis (5) Categorical feature: lifecycle:transition, Index position in categorical data list: 21\n",
      "Sepsis (5) Total Amount of Category labels: 3\n",
      "Sepsis (5) Categorical feature: Diagnose, Index position in categorical data list: 22\n",
      "Sepsis (5) Total Amount of Category labels: 117\n",
      "Sepsis (5) Categorical feature: Hypoxie, Index position in categorical data list: 23\n",
      "Sepsis (5) Total Amount of Category labels: 5\n",
      "Sepsis (5) Categorical feature: DiagnosticUrinarySediment, Index position in categorical data list: 24\n",
      "Sepsis (5) Total Amount of Category labels: 5\n",
      "Sepsis (5) Categorical feature: DiagnosticECG, Index position in categorical data list: 25\n",
      "Sepsis (5) Total Amount of Category labels: 5\n",
      "\n",
      "\n",
      "Sepsis (5) Numerical feature: case_elapsed_time, Index position in categorical data list: 0\n",
      "Sepsis (5) Amount Category Lables: 1\n",
      "Sepsis (5) Numerical feature: event_elapsed_time, Index position in categorical data list: 1\n",
      "Sepsis (5) Amount Category Lables: 1\n",
      "Sepsis (5) Numerical feature: day_in_week, Index position in categorical data list: 2\n",
      "Sepsis (5) Amount Category Lables: 1\n",
      "Sepsis (5) Numerical feature: seconds_in_day, Index position in categorical data list: 3\n",
      "Sepsis (5) Amount Category Lables: 1\n",
      "Sepsis (5) Numerical feature: Age, Index position in categorical data list: 4\n",
      "Sepsis (5) Amount Category Lables: 1\n",
      "Sepsis (5) Numerical feature: Leucocytes, Index position in categorical data list: 5\n",
      "Sepsis (5) Amount Category Lables: 1\n",
      "Sepsis (5) Numerical feature: CRP, Index position in categorical data list: 6\n",
      "Sepsis (5) Amount Category Lables: 1\n",
      "Sepsis (5) Numerical feature: LacticAcid, Index position in categorical data list: 7\n",
      "Sepsis (5) Amount Category Lables: 1\n"
     ]
    }
   ],
   "source": [
    "# BPIC 17 Dataset Categories, Features:\n",
    "\n",
    "sepsis_all_categories = sepsis_train_dataset.all_categories\n",
    "\n",
    "sepsis_all_categories_cat = sepsis_all_categories[0]\n",
    "print(sepsis_all_categories_cat)\n",
    "\n",
    "sepsis_all_categories_num = sepsis_all_categories[1]\n",
    "print(sepsis_all_categories_num)\n",
    "\n",
    "for i, cat in enumerate(sepsis_all_categories_cat):\n",
    "     print(f\"Sepsis (5) Categorical feature: {cat[0]}, Index position in categorical data list: {i}\")\n",
    "     print(f\"Sepsis (5) Total Amount of Category labels: {cat[1]}\")\n",
    "print('\\n')    \n",
    "for i, num in enumerate(sepsis_all_categories_num):\n",
    "     print(f\"Sepsis (5) Numerical feature: {num[0]}, Index position in categorical data list: {i}\")\n",
    "     print(f\"Sepsis (5) Amount Category Lables: {num[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Features for Encoder and Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-12T17:12:20.007618Z",
     "iopub.status.busy": "2025-02-12T17:12:20.007535Z",
     "iopub.status.idle": "2025-02-12T17:12:20.009801Z",
     "shell.execute_reply": "2025-02-12T17:12:20.009614Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input features encoder:  [['concept:name', 'InfectionSuspected', 'org:group', 'DiagnosticBlood', 'DisfuncOrg', 'SIRSCritTachypnea', 'Hypotensie', 'SIRSCritHeartRate', 'Infusion', 'DiagnosticArtAstrup', 'DiagnosticIC', 'DiagnosticSputum', 'DiagnosticLiquor', 'DiagnosticOther', 'SIRSCriteria2OrMore', 'DiagnosticXthorax', 'SIRSCritTemperature', 'DiagnosticUrinaryCulture', 'SIRSCritLeucos', 'Oligurie', 'DiagnosticLacticAcid', 'lifecycle:transition', 'Diagnose', 'Hypoxie', 'DiagnosticUrinarySediment', 'DiagnosticECG'], ['case_elapsed_time', 'event_elapsed_time', 'day_in_week', 'seconds_in_day', 'Age', 'Leucocytes', 'CRP', 'LacticAcid']]\n",
      "Features decoder:  [['concept:name', 'InfectionSuspected', 'org:group', 'DiagnosticBlood', 'DisfuncOrg', 'SIRSCritTachypnea', 'Hypotensie', 'SIRSCritHeartRate', 'Infusion', 'DiagnosticArtAstrup', 'DiagnosticIC', 'DiagnosticSputum', 'DiagnosticLiquor', 'DiagnosticOther', 'SIRSCriteria2OrMore', 'DiagnosticXthorax', 'SIRSCritTemperature', 'DiagnosticUrinaryCulture', 'SIRSCritLeucos', 'Oligurie', 'DiagnosticLacticAcid', 'lifecycle:transition', 'Diagnose', 'Hypoxie', 'DiagnosticUrinarySediment', 'DiagnosticECG'], ['case_elapsed_time', 'event_elapsed_time', 'day_in_week', 'seconds_in_day', 'Age', 'Leucocytes', 'CRP', 'LacticAcid']]\n"
     ]
    }
   ],
   "source": [
    "# Create lists with name of Encoder features (input) and decoder features (input & output)\n",
    "\n",
    "# Encoder features:\n",
    "enc_feat_cat = []\n",
    "enc_feat_num = []\n",
    "for cat in sepsis_all_categories_cat:\n",
    "    enc_feat_cat.append(cat[0])\n",
    "for num in sepsis_all_categories_num:\n",
    "    enc_feat_num.append(num[0])\n",
    "enc_feat = [enc_feat_cat, enc_feat_num]\n",
    "print(\"Input features encoder: \", enc_feat)\n",
    "\n",
    "# Decoder features:\n",
    "dec_feat_cat = enc_feat_cat\n",
    "dec_feat_num = enc_feat_num\n",
    "dec_feat = [dec_feat_cat, dec_feat_num]\n",
    "print(\"Features decoder: \", dec_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-12T17:12:20.010557Z",
     "iopub.status.busy": "2025-02-12T17:12:20.010479Z",
     "iopub.status.idle": "2025-02-12T17:12:20.021713Z",
     "shell.execute_reply": "2025-02-12T17:12:20.021481Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set categories:  ([('concept:name', 18, {'Admission IC': 1, 'Admission NC': 2, 'CRP': 3, 'EOS': 4, 'ER Registration': 5, 'ER Sepsis Triage': 6, 'ER Triage': 7, 'IV Antibiotics': 8, 'IV Liquid': 9, 'LacticAcid': 10, 'Leucocytes': 11, 'Release A': 12, 'Release B': 13, 'Release C': 14, 'Release D': 15, 'Release E': 16, 'Return ER': 17}), ('InfectionSuspected', 5, {'EOS': 1, 'False': 2, 'True': 3, nan: 4}), ('org:group', 27, {'?': 1, 'A': 2, 'B': 3, 'C': 4, 'D': 5, 'E': 6, 'EOS': 7, 'F': 8, 'G': 9, 'H': 10, 'I': 11, 'J': 12, 'K': 13, 'L': 14, 'M': 15, 'N': 16, 'O': 17, 'P': 18, 'Q': 19, 'R': 20, 'S': 21, 'T': 22, 'U': 23, 'V': 24, 'W': 25, 'Y': 26}), ('DiagnosticBlood', 5, {'EOS': 1, 'False': 2, 'True': 3, nan: 4}), ('DisfuncOrg', 5, {'EOS': 1, 'False': 2, 'True': 3, nan: 4}), ('SIRSCritTachypnea', 5, {'EOS': 1, 'False': 2, 'True': 3, nan: 4}), ('Hypotensie', 5, {'EOS': 1, 'False': 2, 'True': 3, nan: 4}), ('SIRSCritHeartRate', 5, {'EOS': 1, 'False': 2, 'True': 3, nan: 4}), ('Infusion', 5, {'EOS': 1, 'False': 2, 'True': 3, nan: 4}), ('DiagnosticArtAstrup', 5, {'EOS': 1, 'False': 2, 'True': 3, nan: 4}), ('DiagnosticIC', 5, {'EOS': 1, 'False': 2, 'True': 3, nan: 4}), ('DiagnosticSputum', 5, {'EOS': 1, 'False': 2, 'True': 3, nan: 4}), ('DiagnosticLiquor', 5, {'EOS': 1, 'False': 2, 'True': 3, nan: 4}), ('DiagnosticOther', 5, {'EOS': 1, 'False': 2, 'True': 3, nan: 4}), ('SIRSCriteria2OrMore', 5, {'EOS': 1, 'False': 2, 'True': 3, nan: 4}), ('DiagnosticXthorax', 5, {'EOS': 1, 'False': 2, 'True': 3, nan: 4}), ('SIRSCritTemperature', 5, {'EOS': 1, 'False': 2, 'True': 3, nan: 4}), ('DiagnosticUrinaryCulture', 5, {'EOS': 1, 'False': 2, 'True': 3, nan: 4}), ('SIRSCritLeucos', 5, {'EOS': 1, 'False': 2, 'True': 3, nan: 4}), ('Oligurie', 5, {'EOS': 1, 'False': 2, 'True': 3, nan: 4}), ('DiagnosticLacticAcid', 5, {'EOS': 1, 'False': 2, 'True': 3, nan: 4}), ('lifecycle:transition', 3, {'EOS': 1, 'complete': 2}), ('Diagnose', 117, {'AA': 1, 'AC': 2, 'AD': 3, 'AE': 4, 'B': 5, 'BB': 6, 'BC': 7, 'BD': 8, 'C': 9, 'CA': 10, 'CB': 11, 'CC': 12, 'CD': 13, 'D': 14, 'DB': 15, 'DD': 16, 'DE': 17, 'E': 18, 'EA': 19, 'EC': 20, 'ED': 21, 'EE': 22, 'EOS': 23, 'F': 24, 'FA': 25, 'FC': 26, 'FD': 27, 'FE': 28, 'G': 29, 'GA': 30, 'GB': 31, 'GC': 32, 'GD': 33, 'GE': 34, 'H': 35, 'HA': 36, 'HB': 37, 'HC': 38, 'HD': 39, 'HE': 40, 'I': 41, 'IA': 42, 'IC': 43, 'J': 44, 'JC': 45, 'JE': 46, 'K': 47, 'KA': 48, 'KB': 49, 'KC': 50, 'KD': 51, 'L': 52, 'LA': 53, 'LB': 54, 'LC': 55, 'LD': 56, 'LE': 57, 'M': 58, 'MA': 59, 'MB': 60, 'MC': 61, 'MD': 62, 'ME': 63, 'N': 64, 'NB': 65, 'NC': 66, 'ND': 67, 'O': 68, 'OB': 69, 'OC': 70, 'OD': 71, 'OE': 72, 'P': 73, 'PC': 74, 'PD': 75, 'Q': 76, 'QB': 77, 'QD': 78, 'QE': 79, 'R': 80, 'RA': 81, 'RB': 82, 'RC': 83, 'RD': 84, 'S': 85, 'SA': 86, 'SB': 87, 'SD': 88, 'T': 89, 'TB': 90, 'U': 91, 'UA': 92, 'UC': 93, 'UD': 94, 'V': 95, 'VA': 96, 'VB': 97, 'VD': 98, 'W': 99, 'WA': 100, 'WB': 101, 'WC': 102, 'WD': 103, 'X': 104, 'XA': 105, 'XB': 106, 'XC': 107, 'XD': 108, 'Y': 109, 'YA': 110, 'YC': 111, 'Z': 112, 'ZA': 113, 'ZB': 114, 'ZD': 115, nan: 116}), ('Hypoxie', 5, {'EOS': 1, 'False': 2, 'True': 3, nan: 4}), ('DiagnosticUrinarySediment', 5, {'EOS': 1, 'False': 2, 'True': 3, nan: 4}), ('DiagnosticECG', 5, {'EOS': 1, 'False': 2, 'True': 3, nan: 4})], [('case_elapsed_time', 1, {}), ('event_elapsed_time', 1, {}), ('day_in_week', 1, {}), ('seconds_in_day', 1, {}), ('Age', 1, {}), ('Leucocytes', 1, {}), ('CRP', 1, {}), ('LacticAcid', 1, {})])\n",
      "Encoder input features:  [['concept:name', 'InfectionSuspected', 'org:group', 'DiagnosticBlood', 'DisfuncOrg', 'SIRSCritTachypnea', 'Hypotensie', 'SIRSCritHeartRate', 'Infusion', 'DiagnosticArtAstrup', 'DiagnosticIC', 'DiagnosticSputum', 'DiagnosticLiquor', 'DiagnosticOther', 'SIRSCriteria2OrMore', 'DiagnosticXthorax', 'SIRSCritTemperature', 'DiagnosticUrinaryCulture', 'SIRSCritLeucos', 'Oligurie', 'DiagnosticLacticAcid', 'lifecycle:transition', 'Diagnose', 'Hypoxie', 'DiagnosticUrinarySediment', 'DiagnosticECG'], ['case_elapsed_time', 'event_elapsed_time', 'day_in_week', 'seconds_in_day', 'Age', 'Leucocytes', 'CRP', 'LacticAcid']]\n",
      "Decoder input+output features:  [['concept:name', 'InfectionSuspected', 'org:group', 'DiagnosticBlood', 'DisfuncOrg', 'SIRSCritTachypnea', 'Hypotensie', 'SIRSCritHeartRate', 'Infusion', 'DiagnosticArtAstrup', 'DiagnosticIC', 'DiagnosticSputum', 'DiagnosticLiquor', 'DiagnosticOther', 'SIRSCriteria2OrMore', 'DiagnosticXthorax', 'SIRSCritTemperature', 'DiagnosticUrinaryCulture', 'SIRSCritLeucos', 'Oligurie', 'DiagnosticLacticAcid', 'lifecycle:transition', 'Diagnose', 'Hypoxie', 'DiagnosticUrinarySediment', 'DiagnosticECG'], ['case_elapsed_time', 'event_elapsed_time', 'day_in_week', 'seconds_in_day', 'Age', 'Leucocytes', 'CRP', 'LacticAcid']]\n",
      "\n",
      "\n",
      "Sequence length of decoder output:  4\n",
      "\n",
      "\n",
      "Cells hidden size:  128\n",
      "Number of LSTM layer:  2\n",
      "Dropout rate:  0.1\n",
      "\n",
      "\n",
      "Encoder number of labels for each input feature (categorical, numerical):  [[18, 5, 27, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 3, 117, 5, 5, 5], [1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "Encoder indices of tensors in dataset used as input:  [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], [0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "Embeddings encoder:  ModuleList(\n",
      "  (0): Embedding(18, 8)\n",
      "  (1): Embedding(5, 4)\n",
      "  (2): Embedding(27, 10)\n",
      "  (3-20): 18 x Embedding(5, 4)\n",
      "  (21): Embedding(3, 3)\n",
      "  (22): Embedding(117, 23)\n",
      "  (23-25): 3 x Embedding(5, 4)\n",
      ")\n",
      "Total embedding feature size encoder:  132\n",
      "Total numerical feature size encoder:  8\n",
      "Input feature size encoder:  140\n",
      "Encoder initialized! \n",
      "\n",
      "Decoder label values size for each categorical input feature:  [18, 5, 27, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 3, 117, 5, 5, 5]\n",
      "Decoder label values size for each numerical input feature:  [1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Decoder indices of tensors in dataset used as input:  [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], [0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "Embeddings decoder:  ModuleList(\n",
      "  (0): Embedding(18, 8)\n",
      "  (1): Embedding(5, 4)\n",
      "  (2): Embedding(27, 10)\n",
      "  (3-20): 18 x Embedding(5, 4)\n",
      "  (21): Embedding(3, 3)\n",
      "  (22): Embedding(117, 23)\n",
      "  (23-25): 3 x Embedding(5, 4)\n",
      ")\n",
      "Total embedding feature size decoder:  132\n",
      "Total numerical feature size decoder:  8\n",
      "Input feature size decoder:  140\n",
      "Output feature list of dicts (featue name, feature output size) of decoder:  [{'concept:name': 18, 'InfectionSuspected': 5, 'org:group': 27, 'DiagnosticBlood': 5, 'DisfuncOrg': 5, 'SIRSCritTachypnea': 5, 'Hypotensie': 5, 'SIRSCritHeartRate': 5, 'Infusion': 5, 'DiagnosticArtAstrup': 5, 'DiagnosticIC': 5, 'DiagnosticSputum': 5, 'DiagnosticLiquor': 5, 'DiagnosticOther': 5, 'SIRSCriteria2OrMore': 5, 'DiagnosticXthorax': 5, 'SIRSCritTemperature': 5, 'DiagnosticUrinaryCulture': 5, 'SIRSCritLeucos': 5, 'Oligurie': 5, 'DiagnosticLacticAcid': 5, 'lifecycle:transition': 3, 'Diagnose': 117, 'Hypoxie': 5, 'DiagnosticUrinarySediment': 5, 'DiagnosticECG': 5}, {'case_elapsed_time': 1, 'event_elapsed_time': 1, 'day_in_week': 1, 'seconds_in_day': 1, 'Age': 1, 'Leucocytes': 1, 'CRP': 1, 'LacticAcid': 1}]\n",
      "Decoder initialized! \n",
      "\n",
      "Output feature list of dicts (featue name, tensor index in dataset) of decoder:  [{'concept:name': 0, 'InfectionSuspected': 1, 'org:group': 2, 'DiagnosticBlood': 3, 'DisfuncOrg': 4, 'SIRSCritTachypnea': 5, 'Hypotensie': 6, 'SIRSCritHeartRate': 7, 'Infusion': 8, 'DiagnosticArtAstrup': 9, 'DiagnosticIC': 10, 'DiagnosticSputum': 11, 'DiagnosticLiquor': 12, 'DiagnosticOther': 13, 'SIRSCriteria2OrMore': 14, 'DiagnosticXthorax': 15, 'SIRSCritTemperature': 16, 'DiagnosticUrinaryCulture': 17, 'SIRSCritLeucos': 18, 'Oligurie': 19, 'DiagnosticLacticAcid': 20, 'lifecycle:transition': 21, 'Diagnose': 22, 'Hypoxie': 23, 'DiagnosticUrinarySediment': 24, 'DiagnosticECG': 25}, {'case_elapsed_time': 0, 'event_elapsed_time': 1, 'day_in_week': 2, 'seconds_in_day': 3, 'Age': 4, 'Leucocytes': 5, 'CRP': 6, 'LacticAcid': 7}]\n"
     ]
    }
   ],
   "source": [
    "import model.dropout_uncertainty_enc_dec_LSTM.dropout_uncertainty_model\n",
    "importlib.reload(model.dropout_uncertainty_enc_dec_LSTM.dropout_uncertainty_model)\n",
    "from model.dropout_uncertainty_enc_dec_LSTM.dropout_uncertainty_model import DropoutUncertaintyEncoderDecoderLSTM\n",
    "\n",
    "# Prediction decoder output sequence length\n",
    "seq_len_pred = 4\n",
    "\n",
    "# Size hidden layer\n",
    "hidden_size = 128\n",
    "\n",
    "# Number of cells\n",
    "num_layers = 2\n",
    "\n",
    "# Fixed Dropout probability \n",
    "dropout = 0.1\n",
    "\n",
    "# Encoder Decoder model initialization\n",
    "model = DropoutUncertaintyEncoderDecoderLSTM(data_set_categories=sepsis_all_categories,\n",
    "                                             enc_feat=enc_feat,\n",
    "                                             dec_feat=dec_feat,\n",
    "                                             seq_len_pred=seq_len_pred,\n",
    "                                             hidden_size=hidden_size,\n",
    "                                             num_layers=num_layers,\n",
    "                                             dropout=dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Object Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-12T17:12:20.022494Z",
     "iopub.status.busy": "2025-02-12T17:12:20.022411Z",
     "iopub.status.idle": "2025-02-12T17:12:20.024243Z",
     "shell.execute_reply": "2025-02-12T17:12:20.024078Z"
    }
   },
   "outputs": [],
   "source": [
    "import loss.losses\n",
    "importlib.reload(loss.losses)\n",
    "from loss.losses import Loss\n",
    "\n",
    "loss_obj = Loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-12T17:12:20.025044Z",
     "iopub.status.busy": "2025-02-12T17:12:20.024955Z",
     "iopub.status.idle": "2025-02-12T18:21:20.109433Z",
     "shell.execute_reply": "2025-02-12T18:21:20.109169Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cpu\n",
      "Model:  DropoutUncertaintyEncoderDecoderLSTM(\n",
      "  (embeddings_enc): ModuleList(\n",
      "    (0): Embedding(18, 8)\n",
      "    (1): Embedding(5, 4)\n",
      "    (2): Embedding(27, 10)\n",
      "    (3-20): 18 x Embedding(5, 4)\n",
      "    (21): Embedding(3, 3)\n",
      "    (22): Embedding(117, 23)\n",
      "    (23-25): 3 x Embedding(5, 4)\n",
      "  )\n",
      "  (encoder): DropoutUncertaintyLSTMEncoder(\n",
      "    (embeddings): ModuleList(\n",
      "      (0): Embedding(18, 8)\n",
      "      (1): Embedding(5, 4)\n",
      "      (2): Embedding(27, 10)\n",
      "      (3-20): 18 x Embedding(5, 4)\n",
      "      (21): Embedding(3, 3)\n",
      "      (22): Embedding(117, 23)\n",
      "      (23-25): 3 x Embedding(5, 4)\n",
      "    )\n",
      "    (first_layer): DropoutUncertaintyLSTMCell(\n",
      "      (Wi): Linear(in_features=140, out_features=128, bias=True)\n",
      "      (Ui): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (Wf): Linear(in_features=140, out_features=128, bias=True)\n",
      "      (Uf): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (Wc): Linear(in_features=140, out_features=128, bias=True)\n",
      "      (Uc): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (Wo): Linear(in_features=140, out_features=128, bias=True)\n",
      "      (Uo): Linear(in_features=128, out_features=128, bias=True)\n",
      "    )\n",
      "    (hidden_layers): ModuleList(\n",
      "      (0): DropoutUncertaintyLSTMCell(\n",
      "        (Wi): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (Ui): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (Wf): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (Uf): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (Wc): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (Uc): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (Wo): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (Uo): Linear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (embeddings_dec): ModuleList(\n",
      "    (0): Embedding(18, 8)\n",
      "    (1): Embedding(5, 4)\n",
      "    (2): Embedding(27, 10)\n",
      "    (3-20): 18 x Embedding(5, 4)\n",
      "    (21): Embedding(3, 3)\n",
      "    (22): Embedding(117, 23)\n",
      "    (23-25): 3 x Embedding(5, 4)\n",
      "  )\n",
      "  (decoder): DropoutUncertaintyLSTMDecoder(\n",
      "    (embeddings): ModuleList(\n",
      "      (0): Embedding(18, 8)\n",
      "      (1): Embedding(5, 4)\n",
      "      (2): Embedding(27, 10)\n",
      "      (3-20): 18 x Embedding(5, 4)\n",
      "      (21): Embedding(3, 3)\n",
      "      (22): Embedding(117, 23)\n",
      "      (23-25): 3 x Embedding(5, 4)\n",
      "    )\n",
      "    (first_layer): DropoutUncertaintyLSTMCell(\n",
      "      (Wi): Linear(in_features=140, out_features=128, bias=True)\n",
      "      (Ui): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (Wf): Linear(in_features=140, out_features=128, bias=True)\n",
      "      (Uf): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (Wc): Linear(in_features=140, out_features=128, bias=True)\n",
      "      (Uc): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (Wo): Linear(in_features=140, out_features=128, bias=True)\n",
      "      (Uo): Linear(in_features=128, out_features=128, bias=True)\n",
      "    )\n",
      "    (hidden_layers): ModuleList(\n",
      "      (0): DropoutUncertaintyLSTMCell(\n",
      "        (Wi): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (Ui): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (Wf): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (Uf): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (Wc): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (Uc): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (Wo): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (Uo): Linear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (output_layers): ModuleDict(\n",
      "      (concept:name_mean): Linear(in_features=128, out_features=18, bias=True)\n",
      "      (concept:name_var): Linear(in_features=128, out_features=18, bias=True)\n",
      "      (InfectionSuspected_mean): Linear(in_features=128, out_features=5, bias=True)\n",
      "      (InfectionSuspected_var): Linear(in_features=128, out_features=5, bias=True)\n",
      "      (org:group_mean): Linear(in_features=128, out_features=27, bias=True)\n",
      "      (org:group_var): Linear(in_features=128, out_features=27, bias=True)\n",
      "      (DiagnosticBlood_mean): Linear(in_features=128, out_features=5, bias=True)\n",
      "      (DiagnosticBlood_var): Linear(in_features=128, out_features=5, bias=True)\n",
      "      (DisfuncOrg_mean): Linear(in_features=128, out_features=5, bias=True)\n",
      "      (DisfuncOrg_var): Linear(in_features=128, out_features=5, bias=True)\n",
      "      (SIRSCritTachypnea_mean): Linear(in_features=128, out_features=5, bias=True)\n",
      "      (SIRSCritTachypnea_var): Linear(in_features=128, out_features=5, bias=True)\n",
      "      (Hypotensie_mean): Linear(in_features=128, out_features=5, bias=True)\n",
      "      (Hypotensie_var): Linear(in_features=128, out_features=5, bias=True)\n",
      "      (SIRSCritHeartRate_mean): Linear(in_features=128, out_features=5, bias=True)\n",
      "      (SIRSCritHeartRate_var): Linear(in_features=128, out_features=5, bias=True)\n",
      "      (Infusion_mean): Linear(in_features=128, out_features=5, bias=True)\n",
      "      (Infusion_var): Linear(in_features=128, out_features=5, bias=True)\n",
      "      (DiagnosticArtAstrup_mean): Linear(in_features=128, out_features=5, bias=True)\n",
      "      (DiagnosticArtAstrup_var): Linear(in_features=128, out_features=5, bias=True)\n",
      "      (DiagnosticIC_mean): Linear(in_features=128, out_features=5, bias=True)\n",
      "      (DiagnosticIC_var): Linear(in_features=128, out_features=5, bias=True)\n",
      "      (DiagnosticSputum_mean): Linear(in_features=128, out_features=5, bias=True)\n",
      "      (DiagnosticSputum_var): Linear(in_features=128, out_features=5, bias=True)\n",
      "      (DiagnosticLiquor_mean): Linear(in_features=128, out_features=5, bias=True)\n",
      "      (DiagnosticLiquor_var): Linear(in_features=128, out_features=5, bias=True)\n",
      "      (DiagnosticOther_mean): Linear(in_features=128, out_features=5, bias=True)\n",
      "      (DiagnosticOther_var): Linear(in_features=128, out_features=5, bias=True)\n",
      "      (SIRSCriteria2OrMore_mean): Linear(in_features=128, out_features=5, bias=True)\n",
      "      (SIRSCriteria2OrMore_var): Linear(in_features=128, out_features=5, bias=True)\n",
      "      (DiagnosticXthorax_mean): Linear(in_features=128, out_features=5, bias=True)\n",
      "      (DiagnosticXthorax_var): Linear(in_features=128, out_features=5, bias=True)\n",
      "      (SIRSCritTemperature_mean): Linear(in_features=128, out_features=5, bias=True)\n",
      "      (SIRSCritTemperature_var): Linear(in_features=128, out_features=5, bias=True)\n",
      "      (DiagnosticUrinaryCulture_mean): Linear(in_features=128, out_features=5, bias=True)\n",
      "      (DiagnosticUrinaryCulture_var): Linear(in_features=128, out_features=5, bias=True)\n",
      "      (SIRSCritLeucos_mean): Linear(in_features=128, out_features=5, bias=True)\n",
      "      (SIRSCritLeucos_var): Linear(in_features=128, out_features=5, bias=True)\n",
      "      (Oligurie_mean): Linear(in_features=128, out_features=5, bias=True)\n",
      "      (Oligurie_var): Linear(in_features=128, out_features=5, bias=True)\n",
      "      (DiagnosticLacticAcid_mean): Linear(in_features=128, out_features=5, bias=True)\n",
      "      (DiagnosticLacticAcid_var): Linear(in_features=128, out_features=5, bias=True)\n",
      "      (lifecycle:transition_mean): Linear(in_features=128, out_features=3, bias=True)\n",
      "      (lifecycle:transition_var): Linear(in_features=128, out_features=3, bias=True)\n",
      "      (Diagnose_mean): Linear(in_features=128, out_features=117, bias=True)\n",
      "      (Diagnose_var): Linear(in_features=128, out_features=117, bias=True)\n",
      "      (Hypoxie_mean): Linear(in_features=128, out_features=5, bias=True)\n",
      "      (Hypoxie_var): Linear(in_features=128, out_features=5, bias=True)\n",
      "      (DiagnosticUrinarySediment_mean): Linear(in_features=128, out_features=5, bias=True)\n",
      "      (DiagnosticUrinarySediment_var): Linear(in_features=128, out_features=5, bias=True)\n",
      "      (DiagnosticECG_mean): Linear(in_features=128, out_features=5, bias=True)\n",
      "      (DiagnosticECG_var): Linear(in_features=128, out_features=5, bias=True)\n",
      "      (case_elapsed_time_mean): Linear(in_features=128, out_features=1, bias=True)\n",
      "      (case_elapsed_time_var): Linear(in_features=128, out_features=1, bias=True)\n",
      "      (event_elapsed_time_mean): Linear(in_features=128, out_features=1, bias=True)\n",
      "      (event_elapsed_time_var): Linear(in_features=128, out_features=1, bias=True)\n",
      "      (day_in_week_mean): Linear(in_features=128, out_features=1, bias=True)\n",
      "      (day_in_week_var): Linear(in_features=128, out_features=1, bias=True)\n",
      "      (seconds_in_day_mean): Linear(in_features=128, out_features=1, bias=True)\n",
      "      (seconds_in_day_var): Linear(in_features=128, out_features=1, bias=True)\n",
      "      (Age_mean): Linear(in_features=128, out_features=1, bias=True)\n",
      "      (Age_var): Linear(in_features=128, out_features=1, bias=True)\n",
      "      (Leucocytes_mean): Linear(in_features=128, out_features=1, bias=True)\n",
      "      (Leucocytes_var): Linear(in_features=128, out_features=1, bias=True)\n",
      "      (CRP_mean): Linear(in_features=128, out_features=1, bias=True)\n",
      "      (CRP_var): Linear(in_features=128, out_features=1, bias=True)\n",
      "      (LacticAcid_mean): Linear(in_features=128, out_features=1, bias=True)\n",
      "      (LacticAcid_var): Linear(in_features=128, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Train Dataset:  <event_log_loader.new_event_log_loader.EventLogDataset object at 0x12f1d9010>\n",
      "Validation Dataset:  <event_log_loader.new_event_log_loader.EventLogDataset object at 0x12ecb2350>\n",
      "Loss object for method calling:  <loss.losses.Loss object at 0x12f1daa50>\n",
      "Num. feautures that follow log-normal PDF:  ['']\n",
      "regularization:  0.00390625\n",
      "Optimizer:  Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    decoupled_weight_decay: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 1e-05\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Scheduler:  <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x13cc274d0>\n",
      "Epochs:  200\n",
      "Mini baches:  128\n",
      "Shuffle batched dataset:  True\n",
      "Teacher forcing ratio:  0.8\n",
      "Use GradNorm:  False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f784eb4718b4b25ae08cb88935500f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leonurny/.local/share/virtualenvs/Probabilistic_Suffix_Prediction_U-ED-LSTM_-32bEAP25/lib/python3.13/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], Learning Rate: 1e-05, Teacher forcing ratio: 0.8\n",
      "Training: Avg Attenuated Training Loss: 63.0172\n",
      "Validation: Avg Standard Validation Loss: 54.7764\n",
      "Validation: Avg Attenuated Validation Loss: 60.6398\n",
      "Validation Loss for Scheduler: 54.7764\n",
      "saving model\n",
      "Epoch [2/200], Learning Rate: 1e-05, Teacher forcing ratio: 0.8\n",
      "Training: Avg Attenuated Training Loss: 62.2174\n",
      "Validation: Avg Standard Validation Loss: 54.2784\n",
      "Validation: Avg Attenuated Validation Loss: 59.9891\n",
      "Validation Loss for Scheduler: 54.2784\n",
      "saving model\n",
      "Epoch [3/200], Learning Rate: 1e-05, Teacher forcing ratio: 0.8\n",
      "Training: Avg Attenuated Training Loss: 60.9529\n",
      "Validation: Avg Standard Validation Loss: 52.7802\n",
      "Validation: Avg Attenuated Validation Loss: 58.3527\n",
      "Validation Loss for Scheduler: 52.7802\n",
      "saving model\n",
      "Epoch [4/200], Learning Rate: 1e-05, Teacher forcing ratio: 0.8\n",
      "Training: Avg Attenuated Training Loss: 58.1142\n",
      "Validation: Avg Standard Validation Loss: 49.7351\n",
      "Validation: Avg Attenuated Validation Loss: 54.4804\n",
      "Validation Loss for Scheduler: 49.7351\n",
      "saving model\n",
      "Epoch [5/200], Learning Rate: 1e-05, Teacher forcing ratio: 0.8\n",
      "Training: Avg Attenuated Training Loss: 52.8238\n",
      "Validation: Avg Standard Validation Loss: 44.5804\n",
      "Validation: Avg Attenuated Validation Loss: 48.0626\n",
      "Validation Loss for Scheduler: 44.5804\n",
      "saving model\n",
      "Epoch [6/200], Learning Rate: 1e-05, Teacher forcing ratio: 0.8\n",
      "Training: Avg Attenuated Training Loss: 46.6701\n",
      "Validation: Avg Standard Validation Loss: 40.9194\n",
      "Validation: Avg Attenuated Validation Loss: 42.9030\n",
      "Validation Loss for Scheduler: 40.9194\n",
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x10d69bce0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/leonurny/.local/share/virtualenvs/Probabilistic_Suffix_Prediction_U-ED-LSTM_-32bEAP25/lib/python3.13/site-packages/torch/utils/data/dataloader.py\", line 1663, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Users/leonurny/.local/share/virtualenvs/Probabilistic_Suffix_Prediction_U-ED-LSTM_-32bEAP25/lib/python3.13/site-packages/torch/utils/data/dataloader.py\", line 1627, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/Users/leonurny/.pyenv/versions/3.13.1/lib/python3.13/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/Users/leonurny/.pyenv/versions/3.13.1/lib/python3.13/multiprocessing/popen_fork.py\", line 41, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/Users/leonurny/.pyenv/versions/3.13.1/lib/python3.13/multiprocessing/connection.py\", line 1148, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/Users/leonurny/.pyenv/versions/3.13.1/lib/python3.13/selectors.py\", line 398, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "  File \"/Users/leonurny/.local/share/virtualenvs/Probabilistic_Suffix_Prediction_U-ED-LSTM_-32bEAP25/lib/python3.13/site-packages/torch/utils/data/_utils/signal_handling.py\", line 73, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 34704) is killed by signal: Abort trap: 6. \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 61\u001b[39m\n\u001b[32m     47\u001b[39m trainer = Trainer(device=device,\n\u001b[32m     48\u001b[39m                   model=model,\n\u001b[32m     49\u001b[39m                   data_train=sepsis_train_dataset,\n\u001b[32m   (...)\u001b[39m\u001b[32m     57\u001b[39m                   save_model_n_th_epoch = \u001b[32m1\u001b[39m,\n\u001b[32m     58\u001b[39m                   saving_path = \u001b[33m'\u001b[39m\u001b[33mSepsis_full_no_grad_norm_robustness.pkl\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# Train the model:\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m train_attenuated_losses, val_losses, val_attenuated_losses = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Robustness-in-suffix-prediction/ml_models/notebooks/training_variational_dropout/Sepsis/../../../trainer/trainer.py:186\u001b[39m, in \u001b[36mTrainer.train_model\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    182\u001b[39m     cat_losses_dict, num_losses_dict = all_losses_dict\n\u001b[32m    184\u001b[39m \u001b[38;5;66;03m# Standard Training:    \u001b[39;00m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m     all_losses_dict, loss_value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprefixes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprefixes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[43m=\u001b[49m\u001b[43msuffixes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    187\u001b[39m     cat_losses_dict, num_losses_dict = all_losses_dict\n\u001b[32m    189\u001b[39m \u001b[38;5;66;03m# Accumulate the categorical losses\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Robustness-in-suffix-prediction/ml_models/notebooks/training_variational_dropout/Sepsis/../../../trainer/trainer.py:328\u001b[39m, in \u001b[36mTrainer.train_epoch\u001b[39m\u001b[34m(self, prefixes, suffixes)\u001b[39m\n\u001b[32m    315\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    316\u001b[39m \u001b[33;03mTrain the model on batches.\u001b[39;00m\n\u001b[32m    317\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    324\u001b[39m \u001b[33;03m- loss: \u001b[39;00m\n\u001b[32m    325\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    326\u001b[39m \u001b[38;5;66;03m# predictions: List of two Dicts one for categorical (means and vars), one for numerical (means and vars): key: feature name + _mean or _var, value: tensor with dim: seq len x batch size x output feature size\u001b[39;00m\n\u001b[32m    327\u001b[39m \u001b[38;5;66;03m# data_features_indeces_dec: List of two Dicts one for categorical, one for numerical: key: feature name, value: index of tensor in data list\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m predictions, _, _, data_features_indeces_dec= \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprefixes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprefixes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[43m=\u001b[49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mteacher_forcing_ratio\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mteacher_forcing_ratio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[38;5;66;03m# Get cat and num predictions\u001b[39;00m\n\u001b[32m    331\u001b[39m predictions_cat, predictions_num = predictions\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/Probabilistic_Suffix_Prediction_U-ED-LSTM_-32bEAP25/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/Probabilistic_Suffix_Prediction_U-ED-LSTM_-32bEAP25/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Robustness-in-suffix-prediction/ml_models/notebooks/training_variational_dropout/Sepsis/../../../model/dropout_uncertainty_enc_dec_LSTM/dropout_uncertainty_model.py:243\u001b[39m, in \u001b[36mDropoutUncertaintyEncoderDecoderLSTM.forward\u001b[39m\u001b[34m(self, prefixes, suffixes, teacher_forcing_ratio)\u001b[39m\n\u001b[32m    240\u001b[39m validation = \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.training \u001b[38;5;129;01mand\u001b[39;00m suffixes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m              \n\u001b[32m    242\u001b[39m \u001b[38;5;66;03m# Call encoder\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m243\u001b[39m (h_enc, c_enc) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mprefixes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[38;5;66;03m# Get SOS event: Last prefx event:\u001b[39;00m\n\u001b[32m    246\u001b[39m cat_prefixes, num_prefixes = prefixes\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/Probabilistic_Suffix_Prediction_U-ED-LSTM_-32bEAP25/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/Probabilistic_Suffix_Prediction_U-ED-LSTM_-32bEAP25/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Robustness-in-suffix-prediction/ml_models/notebooks/training_variational_dropout/Sepsis/../../../model/dropout_uncertainty_enc_dec_LSTM/dropout_uncertainty_encoder.py:76\u001b[39m, in \u001b[36mDropoutUncertaintyLSTMEncoder.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m     73\u001b[39m prefixes = \u001b[38;5;28mself\u001b[39m.__data_enc_for_model(data=\u001b[38;5;28minput\u001b[39m) \u001b[38;5;66;03m# dim: Tensor: seq_len x batch_size x input feature (cat as embedding) \u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# Outputs: All hidden states of all cells in the layer, h,c: last hidden state and cell state in the layer\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m outputs, (h, c), _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfirst_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mprefixes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[38;5;66;03m# Pass through the remaining LSTM cell: Layer gets for: input: h_n Tensor, hx: (h, c)\u001b[39;00m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.hidden_layers):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/Probabilistic_Suffix_Prediction_U-ED-LSTM_-32bEAP25/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/Probabilistic_Suffix_Prediction_U-ED-LSTM_-32bEAP25/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Robustness-in-suffix-prediction/ml_models/notebooks/training_variational_dropout/Sepsis/../../../model/dropout_uncertainty_enc_dec_LSTM/dropout_uncertainty_LSTM_cell.py:174\u001b[39m, in \u001b[36mDropoutUncertaintyLSTMCell.forward\u001b[39m\u001b[34m(self, input, hx, z)\u001b[39m\n\u001b[32m    170\u001b[39m hn = torch.empty(T, B, \u001b[38;5;28mself\u001b[39m.hidden_size, dtype=\u001b[38;5;28minput\u001b[39m.dtype, device=device) \u001b[38;5;66;03m# dim: seq_len x batch_size x hidden size\u001b[39;00m\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m z \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    173\u001b[39m     \u001b[38;5;66;03m# Masks\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m     zx, zh = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sample_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    175\u001b[39m     zx = [mask.to(device) \u001b[38;5;28;01mfor\u001b[39;00m mask \u001b[38;5;129;01min\u001b[39;00m zx]  \n\u001b[32m    176\u001b[39m     zh = [mask.to(device) \u001b[38;5;28;01mfor\u001b[39;00m mask \u001b[38;5;129;01min\u001b[39;00m zh]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Robustness-in-suffix-prediction/ml_models/notebooks/training_variational_dropout/Sepsis/../../../model/dropout_uncertainty_enc_dec_LSTM/dropout_uncertainty_LSTM_cell.py:115\u001b[39m, in \u001b[36mDropoutUncertaintyLSTMCell._sample_mask\u001b[39m\u001b[34m(self, B)\u001b[39m\n\u001b[32m    112\u001b[39m     zx = (\u001b[32m1\u001b[39m-torch.sigmoid((torch.log(eps) - torch.log(\u001b[32m1\u001b[39m+eps)+ torch.log(ux+eps) - torch.log(\u001b[32m1\u001b[39m-ux+eps))/ t))\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    114\u001b[39m     \u001b[38;5;66;03m# dim: gates x batch_size x input_features\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     zx = (\u001b[32m1\u001b[39m-torch.sigmoid((torch.log(p+eps) - torch.log(\u001b[32m1\u001b[39m-p+eps) + \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mux\u001b[49m\u001b[43m+\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m - torch.log(\u001b[32m1\u001b[39m-ux+eps))/ t)) / (\u001b[32m1\u001b[39m-p)\n\u001b[32m    116\u001b[39m \u001b[38;5;66;03m# dim: gates x batch_size x input_features\u001b[39;00m\n\u001b[32m    117\u001b[39m zh = (\u001b[32m1\u001b[39m-torch.sigmoid((torch.log(p+eps) - torch.log(\u001b[32m1\u001b[39m-p+eps)+ torch.log(uh+eps) - torch.log(\u001b[32m1\u001b[39m-uh+eps))/ t)) / (\u001b[32m1\u001b[39m-p)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import trainer.trainer\n",
    "importlib.reload(trainer.trainer)\n",
    "from trainer.trainer import Trainer\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter(comment=\"Full_Sepsis_no_grad\")\n",
    "\n",
    "# device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Start learning rate\n",
    "learning_rate = 1e-5\n",
    "\n",
    "# Optimizer and Scheduler\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate, weight_decay=0)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, min_lr=1e-10)\n",
    "\n",
    "# Epochs\n",
    "num_epochs = 200\n",
    "\n",
    "# BATCHING does not work currntly with custom implementation\n",
    "batch_size = 128\n",
    "\n",
    "# lambda for L2 (weight, bias, dropout) regularization: According to formula: 1/2N\n",
    "regularization_term = 1.0/(2.0*batch_size)\n",
    "\n",
    "# shuffle data\n",
    "shuffle = True\n",
    "\n",
    "# Teacher forcing: Smaller 0.5 more target events are used for next event prediction.\n",
    "teacher_forcing_ratio = 0.8\n",
    "\n",
    "optimize_values = {\"regularization_term\":regularization_term,\n",
    "                   \"optimizer\":optimizer,\n",
    "                   \"scheduler\": scheduler,\n",
    "                   \"epochs\":num_epochs,\n",
    "                   \"mini_batches\":batch_size,\n",
    "                   \"shuffle\": shuffle,\n",
    "                   \"teacher_forcing_ratio\":teacher_forcing_ratio,}\n",
    "\n",
    "suffix_data_split_value = 4\n",
    "\n",
    "# GradNorm parameter\n",
    "gradNorm = {\"use_gradnorm\":False}\n",
    "\n",
    "trainer = Trainer(device=device,\n",
    "                  model=model,\n",
    "                  data_train=sepsis_train_dataset,\n",
    "                  data_val=sepsis_val_dataset,\n",
    "                  loss_obj=loss_obj,\n",
    "                  log_normal_loss_num_feature=[''],\n",
    "                  optimize_values=optimize_values,\n",
    "                  suffix_data_split_value=suffix_data_split_value,\n",
    "                  writer=writer,\n",
    "                  gradnorm_values=gradNorm,\n",
    "                  save_model_n_th_epoch = 1,\n",
    "                  saving_path = 'Sepsis_full_no_grad_norm_robustness.pkl')\n",
    "\n",
    "# Train the model:\n",
    "train_attenuated_losses, val_losses, val_attenuated_losses = trainer.train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-12T18:21:20.112565Z",
     "iopub.status.busy": "2025-02-12T18:21:20.112250Z",
     "iopub.status.idle": "2025-02-12T18:21:20.365832Z",
     "shell.execute_reply": "2025-02-12T18:21:20.365549Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# After training is finished, plot the loss curves\n",
    "plt.plot(range(1, num_epochs+1), train_attenuated_losses, label='Training Attenuated Loss', color='blue')\n",
    "plt.plot(range(1, num_epochs+1), val_losses, label='Validation Loss', color='orange')\n",
    "plt.plot(range(1, num_epochs+1), val_attenuated_losses, label='Validation Attenuated Loss', color='green')\n",
    "# Labeling x and y axes\n",
    "plt.xlabel('Epochs', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "# Adding title\n",
    "plt.title('Training and Validation Loss Curve', fontsize=14)\n",
    "# Adding legend\n",
    "plt.legend()\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Probabilistic_Suffix_Prediction_U-ED-LSTM_-32bEAP25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "2c5eb6012d8d4712929afc03c24e2b9c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3ac6d33403a445239a74505a27f399a6",
       "placeholder": "",
       "style": "IPY_MODEL_eb60c1b900384f42b2d813d4c2b57a9d",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     },
     "3772109714dc404294dde0e9c556e2f6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6c3699f5dee947ffb83c92fb13f6a694",
       "placeholder": "",
       "style": "IPY_MODEL_ebaee9e6cb4f477ebad1f534661b6403",
       "tabbable": null,
       "tooltip": null,
       "value": "200/200[1:08:59&lt;00:00,20.72s/it]"
      }
     },
     "3ac6d33403a445239a74505a27f399a6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4dbc9e1779bb40abb3dab8d4ba476dda": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8c686c9d4ae1416ba31b5549cd99d118",
       "max": 200,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ef7dac4448d24a9a8aacfbdd385079f8",
       "tabbable": null,
       "tooltip": null,
       "value": 200
      }
     },
     "6c3699f5dee947ffb83c92fb13f6a694": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8c686c9d4ae1416ba31b5549cd99d118": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b7262165645c4ac5bfa0ac27622922eb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "eb60c1b900384f42b2d813d4c2b57a9d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ebaee9e6cb4f477ebad1f534661b6403": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ed28fc6b0e22457689a0a9c41d6e1e1a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2c5eb6012d8d4712929afc03c24e2b9c",
        "IPY_MODEL_4dbc9e1779bb40abb3dab8d4ba476dda",
        "IPY_MODEL_3772109714dc404294dde0e9c556e2f6"
       ],
       "layout": "IPY_MODEL_b7262165645c4ac5bfa0ac27622922eb",
       "tabbable": null,
       "tooltip": null
      }
     },
     "ef7dac4448d24a9a8aacfbdd385079f8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
