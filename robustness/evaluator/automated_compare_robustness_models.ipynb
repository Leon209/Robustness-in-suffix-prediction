{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Automated Robustness Comparison\n",
        "\n",
        "This notebook automatically compares robustness metrics across multiple datasets and attacks.\n",
        "\n",
        "**Features:**\n",
        "- Supports 1-3 models flexibly (usually just U-ED-LSTM, but can compare multiple models)\n",
        "- Automatically processes multiple datasets and attacks\n",
        "- Generates all comparison charts\n",
        "- Saves charts to organized directories in the `img` folder\n",
        "- Provides progress tracking and error handling\n",
        "- Configurable BASE_RESULTS_DIR for benchmarks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration\n",
        "\n",
        "Edit this section to configure your datasets and attacks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# CONFIGURATION: Define attack-to-paths mapping and output paths\n",
        "# ============================================================================\n",
        "\n",
        "# Dictionary mapping attack names to lists of result paths\n",
        "# Each path should be the directory containing robustness_results.pkl\n",
        "# Multiple paths per attack will be treated as multiple models to compare\n",
        "ATTACK_RESULTS = {\n",
        "    # \"last_event_attack\": [\n",
        "    #     \"../../evaluation_results/robustness/sepsis/last_event_attack\",\n",
        "    #     # Add more paths here for comparison (e.g., different model variants)\n",
        "    #     # \"../../evaluation_results/robustness/sepsis/last_event_attack_camargo\",\n",
        "    # ],\n",
        "    \"random_event_attack\": [\n",
        "        \"../../evaluation_results/robustness/sepsis/random_event_attack\",\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Output paths for each attack (relative to OUTPUT_BASE_DIR)\n",
        "# Must be in same order as keys in ATTACK_RESULTS\n",
        "# Format: \"dataset/attack\" or just \"attack\" if no dataset folder needed\n",
        "OUTPUT_PATHS = [\n",
        "    #\"sepsis/last_event_attack\",\n",
        "    \"sepsis/random_event_attack\",\n",
        "]\n",
        "\n",
        "# Base output directory for saved charts (relative to project root)\n",
        "OUTPUT_BASE_DIR = '../../img'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports and Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "sys.path.insert(0, '..')\n",
        "sys.path.insert(0, '../..')\n",
        "\n",
        "from robustness_metrics import (\n",
        "    load_results, prepare_robustness_results, calculate_aggregate_metrics\n",
        ")\n",
        "from robustness_charts import (\n",
        "    generate_all_charts_for_comparison,\n",
        "    generate_summary_table\n",
        ")\n",
        "\n",
        "# Create output directory\n",
        "Path(OUTPUT_BASE_DIR).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Color and marker assignments for models (automatically assigned)\n",
        "MODEL_COLORS = ['blue', 'orange', 'green']\n",
        "MODEL_MARKERS = ['o', 's', '^']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_and_prepare_model_results(result_path, model_name=None):\n",
        "    \"\"\"\n",
        "    Load and prepare results from a direct path.\n",
        "    \n",
        "    Args:\n",
        "        result_path: Full path to directory containing robustness_results.pkl, \n",
        "                     or full path to the .pkl file itself\n",
        "        model_name: Optional model name. If None, auto-generated as \"Model 1\", \"Model 2\", etc.\n",
        "    \n",
        "    Returns:\n",
        "        Tuple of (results_dict, aggregate_data_dict, model_name) or (None, None, None) if not found\n",
        "    \"\"\"\n",
        "    # Construct path to .pkl file if directory path is provided\n",
        "    if result_path.endswith('.pkl'):\n",
        "        results_path = result_path\n",
        "    else:\n",
        "        results_path = os.path.join(result_path, 'robustness_results.pkl')\n",
        "    \n",
        "    # Auto-generate model name if not provided\n",
        "    if model_name is None:\n",
        "        # Extract a default name from path if possible, otherwise use generic\n",
        "        model_name = \"Model\"  # Will be numbered by caller\n",
        "    \n",
        "    if not os.path.exists(results_path):\n",
        "        print(f\"  Warning: Results not found at {results_path}\")\n",
        "        return None, None, None\n",
        "    \n",
        "    try:\n",
        "        results = load_results(results_path)\n",
        "        results = prepare_robustness_results(results, save_path=results_path)\n",
        "        data = calculate_aggregate_metrics(results)\n",
        "        return results, data, model_name\n",
        "    except Exception as e:\n",
        "        print(f\"  Error loading from {results_path}: {e}\")\n",
        "        return None, None, None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Main Automation Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "AUTOMATED ROBUSTNESS COMPARISON\n",
            "================================================================================\n",
            "Attacks: 2\n",
            "  - last_event_attack: 1 result path(s)\n",
            "  - random_event_attack: 1 result path(s)\n",
            "Total combinations: 2\n",
            "Output directory: ../../img\n",
            "================================================================================\n",
            "\n",
            "  [1/2] Processing last_event_attack...\n",
            "    Output path: sepsis/last_event_attack\n",
            "    ✓ Generated 12 charts\n",
            "    ✓ Saved to: ../../img/sepsis/last_event_attack/\n",
            "\n",
            "  [2/2] Processing random_event_attack...\n",
            "    Output path: sepsis/random_event_attack\n",
            "  Warning: Results not found at ../../evaluation_results/robustness/sepsis/random_event_attack/robustness_results.pkl\n",
            "    Skipping ../../evaluation_results/robustness/sepsis/random_event_attack: Missing results\n",
            "    Skipping: No models loaded for this attack\n",
            "\n",
            "================================================================================\n",
            "PROCESSING COMPLETE\n",
            "================================================================================\n",
            "Total combinations: 2\n",
            "Successful: 1\n",
            "Failed: 1\n",
            "\n",
            "Failed combinations:\n",
            "  - random_event_attack: No models loaded\n",
            "\n",
            "All charts saved to: ../../img/\n"
          ]
        }
      ],
      "source": [
        "# Validate configuration\n",
        "if len(ATTACK_RESULTS) != len(OUTPUT_PATHS):\n",
        "    raise ValueError(f\"Mismatch: ATTACK_RESULTS has {len(ATTACK_RESULTS)} entries, but OUTPUT_PATHS has {len(OUTPUT_PATHS)} entries. They must match in order.\")\n",
        "\n",
        "# Track progress\n",
        "total_combinations = len(ATTACK_RESULTS)\n",
        "processed = 0\n",
        "successful = 0\n",
        "failed = []\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"AUTOMATED ROBUSTNESS COMPARISON\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Attacks: {len(ATTACK_RESULTS)}\")\n",
        "for attack_name, result_paths in ATTACK_RESULTS.items():\n",
        "    print(f\"  - {attack_name}: {len(result_paths)} result path(s)\")\n",
        "print(f\"Total combinations: {total_combinations}\")\n",
        "print(f\"Output directory: {OUTPUT_BASE_DIR}\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Convert ATTACK_RESULTS to list to maintain order and match with OUTPUT_PATHS\n",
        "attack_items = list(ATTACK_RESULTS.items())\n",
        "\n",
        "for attack_idx, (attack_name, result_paths) in enumerate(attack_items):\n",
        "    processed += 1\n",
        "    \n",
        "    # Get corresponding output path\n",
        "    output_path = OUTPUT_PATHS[attack_idx]\n",
        "    \n",
        "    # Extract dataset and attack from output_path for chart function parameters\n",
        "    # Format: \"dataset/attack\" or just \"attack\"\n",
        "    if '/' in output_path:\n",
        "        dataset, attack = output_path.split('/', 1)\n",
        "    else:\n",
        "        dataset = ''\n",
        "        attack = output_path\n",
        "    \n",
        "    print(f\"\\n  [{processed}/{total_combinations}] Processing {attack_name}...\")\n",
        "    print(f\"    Output path: {output_path}\")\n",
        "    \n",
        "    # Load results for all models from this attack's result paths\n",
        "    loaded_models = []\n",
        "    for path_idx, result_path in enumerate(result_paths):\n",
        "        # Auto-generate model name: \"Model 1\", \"Model 2\", etc.\n",
        "        model_name = f\"Model {path_idx + 1}\"\n",
        "        \n",
        "        results, data, returned_model_name = load_and_prepare_model_results(result_path, model_name)\n",
        "        \n",
        "        if results is None or data is None:\n",
        "            print(f\"    Skipping {result_path}: Missing results\")\n",
        "            continue\n",
        "        \n",
        "        # Add color and marker based on position\n",
        "        model_dict = {\n",
        "            'name': returned_model_name,  # Use 'name' key (not 'model_name') - fixes KeyError\n",
        "            'model_id': f\"model_{path_idx + 1}\",  # Add model_id for wasserstein chart filename\n",
        "            'results': results,\n",
        "            'data': data,\n",
        "            'color': MODEL_COLORS[path_idx % len(MODEL_COLORS)],\n",
        "            'marker': MODEL_MARKERS[path_idx % len(MODEL_MARKERS)]\n",
        "        }\n",
        "        loaded_models.append(model_dict)\n",
        "    \n",
        "    # Check if we have at least one model\n",
        "    if not loaded_models:\n",
        "        print(f\"    Skipping: No models loaded for this attack\")\n",
        "        failed.append((attack_name, \"No models loaded\"))\n",
        "        continue\n",
        "    \n",
        "    try:\n",
        "        # Generate all charts (using extracted dataset/attack for chart function parameters)\n",
        "        charts = generate_all_charts_for_comparison(\n",
        "            dataset, attack, loaded_models, OUTPUT_BASE_DIR\n",
        "        )\n",
        "        \n",
        "        # Generate summary table\n",
        "        summary = generate_summary_table(dataset, attack, loaded_models, OUTPUT_BASE_DIR)\n",
        "        \n",
        "        print(f\"    ✓ Generated {len(charts)} charts\")\n",
        "        print(f\"    ✓ Saved to: {OUTPUT_BASE_DIR}/{output_path}/\")\n",
        "        successful += 1\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"    ✗ Error: {e}\")\n",
        "        failed.append((attack_name, str(e)))\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "# Final summary\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PROCESSING COMPLETE\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Total combinations: {total_combinations}\")\n",
        "print(f\"Successful: {successful}\")\n",
        "print(f\"Failed: {len(failed)}\")\n",
        "\n",
        "if failed:\n",
        "    print(\"\\nFailed combinations:\")\n",
        "    for attack_name, reason in failed:\n",
        "        print(f\"  - {attack_name}: {reason}\")\n",
        "\n",
        "print(f\"\\nAll charts saved to: {OUTPUT_BASE_DIR}/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
